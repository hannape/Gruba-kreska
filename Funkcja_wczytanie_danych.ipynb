{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Funkcja_wczytanie_danych.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNp2lwVl57m1LkVy29WKnkE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hannape/Gruba-kreska/blob/main/Funkcja_wczytanie_danych.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f5ujDUmeuLQ"
      },
      "source": [
        "def funkcja_wczytanie_danych(path_test1618_txt, path_train161718_txt, path_test1618_wav, path_train161718_wav, \\\n",
        "                             balance_types, balance_ratios, chunk_length_ms, chunk_overlap, calls_0, calls_1, \\\n",
        "                             calls_unknown, tolerance, valid_set, test_rec_to_cut, columns_dataframe):\n",
        "\n",
        "  '''\n",
        "  Jest to funkcja zawierająca cały potrzebny kod z pliku Wczytanie_danych, bez zbędnych printów itd.\n",
        "  Args: \n",
        "  te wszystkie parametry wejściowe co powyżej, nie chce mi się ich rozpisywać...\n",
        "  Returns:\n",
        "  file_names_train_set, ind_for_train_set, result_dataframe_train - nazwy nagrań, indeksy chunksów z danego nagrania wybrane do zbioru treningowego (96) + dataframe treningowy\n",
        "  file_names_valid_set, ind_for_valid_set, result_dataframe_valid - nazwy nagrań, indeksy chunksów z danego nagrania wybrane do zbioru walidacyjnego (8) + dataframe walidacyjny\n",
        "  file_names_test_old, ind_for_test_old, result_dataframe_test_old - nazwy nagrań, indeksy chunksów z danego nagrania wybrane do zbioru testowego (20) + dataframe test old\n",
        "  file_names_test_new, ind_for_test_new, result_dataframe_test_new - nazwy nagrań, indeksy chunksów z danego nagrania wybrane do zbioru testowego (18) + dataframe test new\n",
        "\n",
        "  Struktura dataframe:\n",
        "    columns_dataframe = ['chunk_ids', 'chunk_start', 'chunk_end', 'has_bird', 'chunks_species', 'call_id', 'has_unknown', 'has_noise']\n",
        "    result_dataframe_X = pd.DataFrame(data = X, index=file_names_X, columns = columns_dataframe)\n",
        "  '''\n",
        "  ## IMPORTY\n",
        "\n",
        "  import os\n",
        "  import contextlib\n",
        "  import numpy as np\n",
        "  import wave\n",
        "  import math\n",
        "  import pandas as pd\n",
        "  import random\n",
        "  from timeit import default_timer as timer\n",
        "\n",
        "  ### FUNKCJE \n",
        "\n",
        "  def my_read_labels(label_name,path_txt):  # ta sama funkcja co w 1. poprawianie danych\n",
        "      '''Wczytuje etykiety czasowe z pliku labels.txt w folderze train.\n",
        "      \n",
        "      Returns:\n",
        "          ndarray: Tablica z etykietami czasowymi zawierająca kolumny:  sekunda początku dźwięku, sekunda końca dźwięku, gatunek.\n",
        "      '''\n",
        "      labels = []\n",
        "      with open(os.path.join(path_txt, label_name + '.txt'), 'r') as file:\n",
        "          text = file.read()\n",
        "          for line in text.split('\\n')[0:]:\n",
        "              if len(line) > 1:\n",
        "                  start, stop, spec = line.split('\\t')\n",
        "                  #print(start)\n",
        "                  start, stop, spec = float(start), float(stop), str(spec),\n",
        "                  labels.append([start, stop, spec])\n",
        "      return np.array(labels)\n",
        "\n",
        "  def my_check_labels(second, chunk_length_s, labels, tol=0.):\n",
        "      '''Sprawdza czy w ramce czasowej [second, second + chunk_length_s] znajduje się coś wg etykiet `labels`.\n",
        "      \n",
        "      Args:\n",
        "          second (float): Sekunda nagrania.\n",
        "          labels (ndarray): Tablica z etykietami, której 1 kolumna oznacza początek, a 2ga - koniec nagrania.\n",
        "          tol (float): Tolerancja na brzegach fragmentu. Dźwięk, żeby był uznany, musi się kończyć po czasie `second+tol`\n",
        "              lub zaczynać przed czasem `second+chunk_length-tol`.\n",
        "      Returns:\n",
        "          bool: Czy w ramce czasowej jest etykieta - co najmniej 4 ms labelu.\n",
        "  ''' \n",
        "\n",
        "    # jeśli początek etykiety zawiera się w chunku, najpóźniej 4ms przed końcem chunka\n",
        "    # jeśli koniec etykiety zawiera się w chunku, i najwcześniej 4 ms po rozpoczęciu chunka\n",
        "    # jeśli początek etykiety zaczyna się rpzed, a koniec po (w przypadku głosów dłuższych niż chunk length, b. rzadkie przypadki dla 0.5 sek)\n",
        "      return (float(labels[0]) >= second and float(labels[0]) < second + chunk_length_s - tol) or \\\n",
        "            (float(labels[1]) < second + chunk_length_s and float(labels[1]) > second + tol) or \\\n",
        "            (float(labels[0]) < second and float(labels[1]) > second + chunk_length_s)              \n",
        "            #and (labels[2] in calls_to_cut)    # nie sprawdzajmy tu jaka to etykieta jest\n",
        "\n",
        "  def my_map_seconds_to_y(labels, recording_duration, calls_of_interest, calls_to_cut, calls_unknown):  ## Chcemy 500 ms z 150 ms overlapem\n",
        "      '''Tworzy etykiety dla każdego kolejnego chunksa. 1 gdy co najmniej 4 ms etykiety się znajdują w chunksie (gdy urwane dźwięki na brzegach, <4ms - to 0).\n",
        "      \n",
        "      Args:\n",
        "          labels (ndarray): Tablica z etykietami, której 1 kolumna oznacza początek, a druga - koniec nagrania.\n",
        "      Returns:\n",
        "          ndarray: Tablica z binarnymi etykietami.\n",
        "      '''\n",
        "      #STARE: calls_to_cut = ['t', 't?', 't ','t  ', 'g', 'czapla', 'gh', 'g cz', 'puszczyk','gaski','g?','mewa?','zwierzak?','high freq','g niskie','??? mysz']\n",
        "      \n",
        "      \n",
        "      duration_in_ms = recording_duration*1000\n",
        "      nr_of_chunks =  1 + (duration_in_ms - chunk_length_ms) / (chunk_length_ms - chunk_overlap)\n",
        "      #print(\"ilość chunksów w tym nagraniu: \", math.ceil(nr_of_chunks) )\n",
        "      \n",
        "      \n",
        "      y = [0] * math.ceil(nr_of_chunks)             # recording_duration \n",
        "      y_restrictive = [0] * math.ceil(nr_of_chunks) # recording_duration\n",
        "      chunks_start, chunks_end = [0] * math.ceil(nr_of_chunks), [0] * math.ceil(nr_of_chunks)      \n",
        "      has_unknown, has_noise = [0] * math.ceil(nr_of_chunks), [0] * math.ceil(nr_of_chunks)\n",
        "      call_id = [[] for _ in range(math.ceil(nr_of_chunks))]\n",
        "      chunks_species = [[] for _ in range(math.ceil(nr_of_chunks))]\n",
        "      \n",
        "      #print(np.shape(labels))\n",
        "      for s in range(math.ceil(nr_of_chunks)):\n",
        "          chunks_start[s] = s * ((chunk_length_ms-chunk_overlap) / 1000)  # czyli s * 0.35\n",
        "          chunks_end[s] = chunks_start[s] + chunk_length_ms/1000 \n",
        "          for ind,l in enumerate(labels):\n",
        "              #print('label_index: ',ind, ' a label to: ', l[2] )\n",
        "              if my_check_labels(chunks_start[s], chunk_length_ms/1000, l):\n",
        "                  #print(s*0.35)\n",
        "                  if l[2] in calls_to_cut:\n",
        "                    has_noise[s] = 1\n",
        "                  if l[2] in calls_unknown:\n",
        "                    has_unknown[s] = 1\n",
        "                  if l[2] in calls_of_interest:  \n",
        "                    y[s] = 1 \n",
        "  \n",
        "              if my_check_labels(chunks_start[s], chunk_length_ms/1000, l, 0.004): #z tolerancją \n",
        "                  \n",
        "                  if l[2] in calls_to_cut:\n",
        "                    chunks_species[s].append(l[2])\n",
        "                  if l[2] in calls_unknown:\n",
        "                    has_unknown[s] = 1\n",
        "                    chunks_species[s].append(l[2])\n",
        "                  if l[2] in calls_of_interest:  \n",
        "                    y_restrictive[s] = 1  \n",
        "                    chunks_species[s].append(l[2])  \n",
        "                    call_id[s].append(ind)\n",
        "                \n",
        "                        \n",
        "          if y[s] != y_restrictive[s] and l[2] in calls_of_interest:\n",
        "              #print('próbka ', s, 'zaczynajaca sie ', chunks_start[s],', jest unknown, bo za mały fragment głosu nas interesującego')\n",
        "              #print('y[s]:', y[s],'yres:', y_restrictive[s] )\n",
        "              y[s] = 0    # jeśli mniej niż 4 ms fragment, to zakładamy że nie ma głosu, i dajemy unknown także, by nie karać za ewentualne znalezienie tego głosu\n",
        "              has_unknown[s] = 1\n",
        "      #print('Rozmiar ',np.shape([s, chunks_start, chunks_end, y, chunks_species, call_id, has_unknown]))\n",
        "      return s+1, chunks_start, chunks_end, y, chunks_species, call_id, has_unknown, has_noise    \n",
        "\n",
        "  def my_load_wav(path_wav, path_txt, recordings_incl = None, recordings_excl = None):   # dłuższa funkcja niż w 1.\n",
        "\n",
        "    recording_labels_all = []\n",
        "    in_which_recording = []\n",
        "    file_names = []\n",
        "\n",
        "    # wszystkie nagrania\n",
        "    if recordings_incl == None and recordings_excl == None:                                        \n",
        "      rec_files = sorted([file_name for file_name in os.listdir(path_wav) if file_name.endswith('.wav')])\n",
        "\n",
        "    # nagrania tylko te w podanym zbiorze (walid)\n",
        "    if recordings_incl != None:                                                                     \n",
        "      rec_files_all = [file_name for file_name in os.listdir(path_wav) if file_name.endswith('.wav')]\n",
        "      recordings_incl = [s + '.wav' for s in recordings_incl]\n",
        "      rec_files = sorted(list( set.intersection(set(rec_files_all), set(recordings_incl))))\n",
        "\n",
        "    # nagrania oprócz nagrań w podanym zbiorze (train)  \n",
        "    if recordings_excl != None:                                                                     \n",
        "      rec_files_all = [file_name for file_name in os.listdir(path_wav) if file_name.endswith('.wav')]\n",
        "      recordings_excl = [s + '.wav' for s in recordings_excl]\n",
        "      rec_files = sorted(list(set(rec_files_all) - set(recordings_excl))  )\n",
        "    \n",
        "    X_matrix = [[] for _ in range(np.size(rec_files))]\n",
        "    file_names = [[] for _ in range(np.size(rec_files))]\n",
        "\n",
        "    for ind, file_name in enumerate(rec_files):\n",
        "        \n",
        "        print(\"------------Analiza nagrania: \" + file_name + \"-----------\")\n",
        "        recording_id = str(file_name.split('.')[0])\n",
        "        \n",
        "        fname = path_wav + file_name      #print(fname)\n",
        "        with contextlib.closing(wave.open(fname,'r')) as f:\n",
        "            frames = f.getnframes()\n",
        "            rate = f.getframerate()\n",
        "            duration = frames / float(rate)\n",
        "            recording_duration = math.ceil(duration)\n",
        "            #print(\"Czas trwania nagrania - w sekundach: \" + str(recording_duration))\n",
        "            #print(\"rate:\", rate)\n",
        "      \n",
        "        recording_id = (file_name.split('.')[0])       #print(recording_id)\n",
        "        recording_labels = my_read_labels(recording_id, path_txt)    \n",
        "\n",
        "        #print(\"Duration:\", duration)\n",
        "        #y_binary = my_map_seconds_to_y(recording_labels, duration)\n",
        "        chunk_id, chunk_start, chunk_end, has_bird, chunks_species, call_id, has_unknown, has_noise  = my_map_seconds_to_y(recording_labels, duration, calls_1, calls_0, calls_unknown)\n",
        "        chunk_ids = range(chunk_id)\n",
        "        chunk_start = rate*np.array(chunk_start)\n",
        "        chunk_start = [round(num) for num in chunk_start]\n",
        "        chunk_end = rate*np.array(chunk_end)\n",
        "        chunk_end = [round(num) for num in chunk_end]\n",
        "        X_matrix[ind] = [chunk_ids, chunk_start, chunk_end, has_bird, chunks_species, call_id, has_unknown, has_noise]  # !!!! chunk start i end przerzucone na sample !!!!!\n",
        "        file_names[ind] = file_name\n",
        "\n",
        "    return X_matrix , file_names #chunk_id, chunk_start, chunk_end, has_bird, chunks_species, call_id, has_unknown\n",
        "\n",
        "  def find_ratio(recordings_names, path_txt):\n",
        "    count_s,count_k, count_d, count_r, count_positives = 0,0,0,0,0\n",
        "    for rec_name in recordings_names:\n",
        "      recording_labels = my_read_labels(rec_name, path_txt)  \n",
        "      #print(recording_labels)\n",
        "      counted_labels = Counter(recording_labels[:,2])\n",
        "\n",
        "      #print(counted_labels)\n",
        "      for calls in labels_s:\n",
        "        count_s += counted_labels[calls]\n",
        "\n",
        "      for calls in labels_k:\n",
        "        count_k += counted_labels[calls]\n",
        "\n",
        "      for calls in labels_d:\n",
        "        count_d += counted_labels[calls]   \n",
        "\n",
        "      for calls in labels_r:\n",
        "        count_r += counted_labels[calls] \n",
        "\n",
        "      for calls in calls_1:\n",
        "        count_positives += counted_labels[calls] \n",
        "\n",
        "    return [count_s, count_k, count_d, count_r, count_positives]  \n",
        "\n",
        "  def create_set_ind(result_dataframe, balance, ratios = None):\n",
        "    \n",
        "    #print(balance)\n",
        "    file_names = list(result_dataframe.index)\n",
        "    #print(len(file_names))\n",
        "    ind_chosen = [[] for _ in range(len(file_names))]\n",
        "    neg_random_numb = 0;\n",
        "    all_pos = 0\n",
        "    all_chunks = 0\n",
        "\n",
        "\n",
        "    for file_i, file_name in enumerate(file_names):\n",
        "      #print(file_i, ' nagranie ', file_name)\n",
        "      \n",
        "      indices_hasbird = [i for i, j in enumerate(result_dataframe['has_bird'][file_i]) if j == 1]\n",
        "      indices_hasnoise = [i for i, j in enumerate(result_dataframe['has_noise'][file_i]) if j == 1]\n",
        "      indices_unknown = [i for i, j in enumerate(result_dataframe['has_unknown'][file_i]) if j == 1]\n",
        "      indices_all = result_dataframe['chunk_ids'][file_i]\n",
        "      pos = indices_hasbird\n",
        "\n",
        "\n",
        "      if balance == 'full_rec':\n",
        "        \n",
        "        ind_chosen[file_i] = list(set(indices_all) - (set(indices_unknown) - set(indices_hasbird)) )  \n",
        "        # te które mają ptaka i unknown, to zostają. W każdym innym przypadku, unknown wylatuje z setu\n",
        "        #print(np.shape(ind_chosen))\n",
        "        all_pos += len(pos)\n",
        "        all_chunks += len(ind_chosen[file_i])\n",
        "        #print('pos: ', len(indices_hasbird))  # pozytywne\n",
        "        neg_labels = list(set(indices_hasnoise) - set(indices_hasbird +indices_unknown))\n",
        "        #print('neg hałas:' , len(neg_labels))\n",
        "        #print('ind_chosen:' , len(ind_chosen[file_i]))\n",
        "\n",
        "      if balance == 'balanced' or balance == 'valid':\n",
        "        \n",
        "        #print('pos: ', len(indices_hasbird))  # pozytywne\n",
        "        \n",
        "        neg_labels = list(set(indices_hasnoise) - set(indices_hasbird +indices_unknown))\n",
        "        #print('neg hałas:' , len(neg_labels))\n",
        "        #print(len(list(set(indices_hasnoise) - set(indices_hasbird +indices_unknown)))) # z samym hałasem, bez unknown czy ptaków. Czyli 0\n",
        "        #temp =  list(set(indices_hasbird + indices_hasnoise))\n",
        "\n",
        "        \n",
        "        \n",
        "        if (len(pos) - len(neg_labels)>=0):   \n",
        "          neg_random_numb = len(pos) - len(neg_labels)\n",
        "          if (neg_random_numb < ratios[1]):\n",
        "            neg_random_numb = ratios[1]\n",
        "          if neg_random_numb + len(neg_labels) < ratios[0]:\n",
        "            neg_random_numb = ratios[0] - len(neg_labels)\n",
        "        else:\n",
        "          neg_random_numb = ratios[1]\n",
        "\n",
        "        #print('neg random: ', neg_random_numb)\n",
        "\n",
        "        neg_random_set = list(set(indices_all) - (set(indices_unknown + indices_hasbird + indices_hasnoise)))\n",
        "\n",
        "\n",
        "        random.seed(667)  # zmienione, z file_i\n",
        "        neg_random = random.sample(neg_random_set, neg_random_numb)\n",
        "        #print(neg_random[0:5])\n",
        "        ind_chosen[file_i] = sorted(list(set(indices_hasbird + neg_labels + neg_random)))\n",
        "\n",
        "        all_pos += len(pos)\n",
        "        all_chunks += len(ind_chosen[file_i])  \n",
        "\n",
        "    print('wszystkich chunków: ', all_chunks,', w tym ', all_pos, ' pozytywnych. Czyli ', 100* round(all_pos/all_chunks,4),' % pozytywnych w zbiorze', balance )\n",
        "    return file_names, ind_chosen\n",
        "\n",
        "  # trening i walid  \n",
        "\n",
        "  print('*************  Train  ***********')\n",
        "\n",
        "  X_train, file_names_train = my_load_wav(path_train161718_wav, path_train161718_txt, None, valid_set) \n",
        "  result_dataframe_train = pd.DataFrame(data = X_train, index=file_names_train, columns = columns_dataframe)\n",
        "  file_names_train_set, ind_for_train_set = create_set_ind(result_dataframe_train, balance_types[1], balance_ratios[1])\n",
        "\n",
        "  print('*************  Valid  ***********')\n",
        "\n",
        "  X_valid, file_names_valid = my_load_wav(path_train161718_wav, path_train161718_txt, valid_set, None)   \n",
        "  result_dataframe_valid = pd.DataFrame(data = X_valid, index=file_names_valid, columns = columns_dataframe)  \n",
        "  file_names_valid_set, ind_for_valid_set = create_set_ind(result_dataframe_valid, balance_types[2], balance_ratios[2])\n",
        "\n",
        "  # testy\n",
        "\n",
        "  print('*************  Test old  ***********')\n",
        "\n",
        "  X_test_old, file_names_test_old = my_load_wav(path_test1618_wav, path_test1618_txt) \n",
        "  result_dataframe_test_old = pd.DataFrame(data = X_test_old, index=file_names_test_old, columns = columns_dataframe)\n",
        "  file_names_test_set_old, ind_for_test_set_old = create_set_ind(result_dataframe_test_old, balance_types[0], balance_ratios[0])\n",
        "\n",
        "  print('*************  Test new  ***********')\n",
        " \n",
        "  X_test_new, file_names_test_new = my_load_wav(path_test1618_wav, path_test1618_txt, None, test_rec_to_cut)\n",
        "  result_dataframe_test_new = pd.DataFrame(data = X_test_new, index=file_names_test_new, columns = columns_dataframe)\n",
        "  file_names_test_set_new, ind_for_test_set_new = create_set_ind(result_dataframe_test_new, balance_types[0], balance_ratios[0])\n",
        "\n",
        "\n",
        "  return [[file_names_train_set, ind_for_train_set, result_dataframe_train],[file_names_valid_set, ind_for_valid_set, result_dataframe_valid],\n",
        "          [file_names_test_set_old, ind_for_test_set_old, result_dataframe_test_old], [file_names_test_set_new, ind_for_test_set_new, result_dataframe_test_new]]"
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}