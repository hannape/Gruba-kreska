{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Funkcja_reprezentacje.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/BvwlPbFTDAdia9HQ7Xq1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hannape/Gruba-kreska/blob/main/Funkcja_reprezentacje.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8UDnWboMeRW"
      },
      "source": [
        "def funkcja_reprezentacje(path_wav, data_settype, representation_type, repr_1d_summary, summary_1d, sr, chunk_length_ms, \\\r\n",
        "                          n_fft, win_length, hop_length, window, f_min, f_max, n_mels, N, step, Np, K, tm, flock, tlock):\r\n",
        "   \r\n",
        "  '''\r\n",
        "  Jest to funkcja zawierająca cały potrzebny kod z pliku 'reprezentacja śmieci/Untitled1', bez zbędnych printów, komentarzy itd.\r\n",
        "\r\n",
        "  Args: \r\n",
        "    te wszystkie parametry wejściowe co powyżej, opisane w miarę w mainie\r\n",
        "\r\n",
        "  Returns:\r\n",
        "    file_names_train_set - nazwy nagrań wchodzące w skład zbioru\r\n",
        "    ind_for_train_set - indeksy chunksów wybrane z poszczególnych nagrań\r\n",
        "    info_chunksy - informacje o wybranych chunksach - te dane co wcześniej w dataframe, ale tylko dla wybranych chunksów \r\n",
        "      ['chunk_ids', 'chunk_start', 'chunk_end', 'has_bird', 'chunks_species', 'call_id', 'has_unknown', 'has_noise']\r\n",
        "    representation_type - - to co na wejściu było, jaki jeden z pięciu typów reprezentacji\r\n",
        "    repr_full  - wybrana reprezentacja dla każdego z wybranych chunksów z nagrań. Rozmiary:\r\n",
        "      spektrogram: 1 nagranie - chunksy x 63 x 148\r\n",
        "      mel-spektrogram: 1 nagranie - chunksy x 60 x 148\r\n",
        "      multitaper: 1 nagranie - chunksy x 64 x 149\r\n",
        "      8_classic: 1 nagranie - chunksy x 1-4 x 8\r\n",
        "      8_classic_plus_MIR: 1 nagranie - chunksy x 1-4 x 39\r\n",
        "\r\n",
        "  ''' \r\n",
        "  ## IMPORTY\r\n",
        "\r\n",
        "  import os\r\n",
        "  import contextlib\r\n",
        "  import numpy as np\r\n",
        "  import wave\r\n",
        "  import math\r\n",
        "  import pandas as pd\r\n",
        "  import random\r\n",
        "  from timeit import default_timer as timer\r\n",
        "  from scipy.stats.mstats import gmean\r\n",
        "  from statistics import mean\r\n",
        "  from matplotlib import cm\r\n",
        "  import librosa\r\n",
        "  import matplotlib.pyplot as plt\r\n",
        "  import libtfr\r\n",
        "  import time\r\n",
        "\r\n",
        "  \r\n",
        "  # nie powinno mieć to wszystko train w nazwie, no ale już trudno. Chodzi o dowolny dataset który będzie na wejściu \r\n",
        "  # z funkcji wczytanie:\r\n",
        "  file_names_train_set = data_settype[0]\r\n",
        "  ind_for_train_set = data_settype[1]\r\n",
        "  result_dataframe_train = data_settype[2]  # trzeba powyciągać tylko interesujące nas chunksy\r\n",
        "  df_to_np = result_dataframe_train.to_numpy()  # bo nie umiem sobie poradiś jak jest to df, wiele funkcji które chcę użyć nie działa\r\n",
        "\r\n",
        "  repr_full = [[] for _ in range(np.shape(file_names_train_set)[0])]\r\n",
        "  info_chunksy = [[[] for _ in range(8)] for _ in range(np.shape(file_names_train_set)[0])]  # 8 kolumn w dataframie było\r\n",
        "  indices = data_settype[1]\r\n",
        "  print(file_names_train_set) \r\n",
        "\r\n",
        "  # k - kolejne nagrania w zbiorze \r\n",
        "  for k in range(0,np.shape(file_names_train_set)[0]): #np.shape(file_names_train_set)[0]):  # 87 dla zbioru train\r\n",
        "\r\n",
        "    ##### pętla do wycięgnięcia info o interesujących chunksach\r\n",
        "    empty_list = ([[] for _ in range(np.shape(indices[k])[0])])\r\n",
        "    # warunki: bo może się zdarzyć że macierz tablica pustych elementów będzie w tych dwóch 'chunks_species', 'call_id', i wtedy np.take nie działa \r\n",
        "    if not any(df_to_np[k][4]) and not any(df_to_np[k][5]):  \r\n",
        "      info_chunksy[k] = [np.take(df_to_np[k][0],indices[k]), np.take(df_to_np[k][1],indices[k]), np.take(df_to_np[k][2],indices[k]), np.take(df_to_np[k][3],indices[k]), \\\r\n",
        "                        empty_list, empty_list, np.take(df_to_np[k][6],indices[k]), np.take(df_to_np[k][7],indices[k])]\r\n",
        "      print(np.shape(info_chunksy[k][5]), 'no calls at all')\r\n",
        "    elif not any(df_to_np[k][5]):\r\n",
        "      info_chunksy[k] = [np.take(df_to_np[k][0],indices[k]), np.take(df_to_np[k][1],indices[k]), np.take(df_to_np[k][2],indices[k]), np.take(df_to_np[k][3],indices[k]), \\\r\n",
        "                        np.take(df_to_np[k][4],indices[k]).tolist(), empty_list, np.take(df_to_np[k][6],indices[k]), np.take(df_to_np[k][7],indices[k])]\r\n",
        "      print(np.shape(info_chunksy[k][5]), 'no calls of interest')\r\n",
        "    else:\r\n",
        "      info_chunksy[k] = [np.take(df_to_np[k][0],indices[k]), np.take(df_to_np[k][1],indices[k]), np.take(df_to_np[k][2],indices[k]), np.take(df_to_np[k][3],indices[k]), \\\r\n",
        "                        np.take(df_to_np[k][4],indices[k]).tolist(), np.take(df_to_np[k][5],indices[k]).tolist(), np.take(df_to_np[k][6],indices[k]), np.take(df_to_np[k][7],indices[k])]  \r\n",
        "\r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    repr = [[] for _ in range(np.shape(ind_for_train_set[k])[0])]\r\n",
        "    #print(path_wav, file_names_train_set[k])\r\n",
        "    #print(ind_for_train_set[k])\r\n",
        "    ##### a to już pętla do reprezentacji, pojedyncze chunksy\r\n",
        "    for num, i in enumerate(ind_for_train_set[k]):                        # 262 dla pierwszego nagrania w zbiorze train, bo tyle mamy tam chunksów\r\n",
        "      \r\n",
        "      # wczytanie chunka naszego półsekundowego:\r\n",
        "      y, sr = librosa.load(path_wav + file_names_train_set[k], sr = 44100, offset = result_dataframe_train['chunk_start'][k][i]/sr, duration = chunk_length_ms/1000)\r\n",
        "      \r\n",
        "      ####### W zależności od reprezentacji: \r\n",
        "      \r\n",
        "      ####### reprezentacja 1  ------- 63 x 148 ------ SPEKTROGRAM\r\n",
        "      if representation_type=='spektrogram':\r\n",
        "      \r\n",
        "        stft = librosa.stft(y, n_fft=n_fft, win_length=win_length, hop_length=hop_length, window= window) # krótkoczasowa transformata fouriera STFT\r\n",
        "        stft1 = librosa.amplitude_to_db(np.abs(stft)**2)                                              # kwadrat wartości bezwzględnej plus przerzucenie na skalę decybelową\r\n",
        "        freqs = librosa.core.fft_frequencies(n_fft=n_fft, sr=sr)                             # wyznaczenie częstotliwości\r\n",
        "        x,  = np.where( freqs >= min(freqs[(freqs >= f_min)]))\r\n",
        "        j,  = np.where( freqs <= max(freqs[(freqs <= f_max)]))\r\n",
        "        stft1 = stft1[min(x):max(j),]                                                        # stft tylko w wybranym zakresie\r\n",
        "        #freqs1 = freqs[min(x):max(j),]\r\n",
        "        repr1_spectro = stft1\r\n",
        "        repr[num] = repr1_spectro\r\n",
        "\r\n",
        "      ####### reprezentacja 2 (3 V3) - mel spektrogram  ------- 60 x 148 ------  \r\n",
        "      if representation_type=='mel-spektrogram':\r\n",
        "        # to chyba wzięte było z birdvoxa\r\n",
        "\r\n",
        "        stft = librosa.stft(np.array(y), n_fft=n_fft, win_length=win_length, hop_length= hop_length, window=window)\r\n",
        "        abs2_stft = (stft.real*stft.real) + (stft.imag*stft.imag)\r\n",
        "        melspect = librosa.feature.melspectrogram(y=None, S=abs2_stft, sr=sr, n_mels= n_mels, fmin = f_min, fmax=f_max, hop_length=hop_length, n_fft=n_fft)\r\n",
        "        repr2_melspec = 0.5 * librosa.amplitude_to_db(melspect, ref=1.0)\r\n",
        "        repr[num] = repr2_melspec\r\n",
        "\r\n",
        "      ####### reprezentacja 3 (5b) - multitaper o większej rozdzielczości ------- 64 x 149 ------\r\n",
        "      # Ale tak naprawdę to nie jest multitaper, ale coś innego, nie wiem w sumie do końca co. Time-frequency reassignement spectrogram? DOCZYTAĆ\r\n",
        "      if representation_type=='multitaper':\r\n",
        "        result5b = libtfr.tfr_spec(y, N = N, step = step, Np = Np, K = 2, tm = tm, flock = flock, tlock = tlock)     \r\n",
        "        freqs, ind = libtfr.fgrid(sr, N, fpass=(f_min,f_max)) \r\n",
        "        repr3_multitaper = result5b[ind,]; # tylko interesujące nas pasmo\r\n",
        "        repr[num] = repr3_multitaper\r\n",
        "\r\n",
        "      if representation_type=='8_classic' or representation_type=='8_classic_plus_MIR':\r\n",
        "\r\n",
        "        S1 = np.abs(librosa.stft(np.array(y), n_fft=n_fft, win_length=win_length, hop_length= hop_length, window=window))\r\n",
        "        freqs = librosa.core.fft_frequencies(n_fft=n_fft, sr=sr) \r\n",
        "        o,  = np.where( freqs >= min(freqs[(freqs >= f_min)]))\r\n",
        "        j,  = np.where( freqs <= max(freqs[(freqs <= f_max)]))\r\n",
        "        freqs1 = freqs[min(o):max(j),]\r\n",
        "        S = S1[min(o):max(j),] \r\n",
        "\r\n",
        "        param_0 = np.sum(S, axis=0)             #librosa.feature.spectral_bandwidth(S=S, p = 1)  # moc sygnału. Ale z wartości absolutnej spektorgramu, bez tego kwadratu jeszcz\r\n",
        "        param_1 = librosa.feature.spectral_centroid(S=S, freq=freqs1)                            # centroid https://www.mathworks.com/help/audio/ref/spectralcentroid.html\r\n",
        "        param_2 = np.power(librosa.feature.spectral_bandwidth(S=S, freq=freqs1, p = 2),2)        # 2 rzędu  \r\n",
        "        param_3 = np.power(librosa.feature.spectral_bandwidth(S=S, freq=freqs1, p = 3),3)        # 3 rzędu\r\n",
        "        param_4 = np.power(librosa.feature.spectral_bandwidth(S=S, freq=freqs1, p = 4),4)        # 4 rzędu\r\n",
        "        skosnosc = param_3[0] / np.power(param_2[0],1.5)                        # https://www.mathworks.com/help/audio/ref/spectralskewness.html #skosnosc2 = skew(S, axis=0)\r\n",
        "        kurtoza =  param_4[0]/ np.power(param_2[0],2) - 3                       #kurtoza2 = kurtosis(S, axis=0)\r\n",
        "        plaskosc = librosa.feature.spectral_flatness(S=S)                       #gmean(S_squared)/np.mean(S_squared)\r\n",
        "        nb_summary = np.sum(summary_1d)\r\n",
        "                \r\n",
        "        if representation_type=='8_classic_plus_MIR':\r\n",
        " \r\n",
        "          def FeatureSpectralFlux(X):  #https://www.audiocontentanalysis.org/code/audio-features/spectral-flux-2/\r\n",
        "            # difference spectrum (set first diff to zero)\r\n",
        "            X = np.c_[X[:, 0], X]\r\n",
        "            afDeltaX = np.diff(X, 1, axis=1)\r\n",
        "            # flux\r\n",
        "            vsf = np.sqrt((afDeltaX**2).sum(axis=0)) / X.shape[0]\r\n",
        "            return  vsf[1:]                 # pozbycie się pierwszego elementu, który zawsze jest zerem , np.squeeze(vsf[1:]) if isSpectrum else\r\n",
        "          \r\n",
        "          stft = librosa.stft(np.array(y), n_fft=n_fft, win_length=win_length, hop_length= hop_length, window=window)\r\n",
        "          abs2_stft = (stft.real*stft.real) + (stft.imag*stft.imag)\r\n",
        "          melspect = librosa.feature.melspectrogram(y=None, S=abs2_stft, sr=sr, n_mels= n_mels, fmin = f_min, fmax=f_max, hop_length=hop_length, n_fft=n_fft)\r\n",
        "          \r\n",
        "          mfccs =librosa.feature.mfcc(S=librosa.power_to_db(melspect), n_mfcc=12)\r\n",
        "          mfcc_delta = librosa.feature.delta(mfccs)\r\n",
        "          zcr = sum(librosa.feature.zero_crossing_rate(y, frame_length=win_length, hop_length= hop_length))  #  ZCR can be interpreted as a measure of the noisiness of a signal. For example, it usually exhibits higher values in the case of noisy signals. It is also known to reflect, in a rather coarse manner, the spectral characteristics of a signal. std to recognize speech vs music\r\n",
        "          contrast = librosa.feature.spectral_contrast(S=S, hop_length=hop_length, n_fft=n_fft, n_bands = 2, fmin = f_min)\r\n",
        "          rolloff = librosa.feature.spectral_rolloff(S=S, hop_length=hop_length, n_fft=n_fft, roll_percent=0.85)    \r\n",
        "          rms = librosa.feature.rms(S=S, hop_length=hop_length, frame_length = 124) \r\n",
        "          spectral_flux = FeatureSpectralFlux(S)\r\n",
        "          np.shape(rms)\r\n",
        "          paramsy = [[[] for _ in range(39)] for _ in range(nb_summary)]\r\n",
        "          idx = 0\r\n",
        "\r\n",
        "          for m in range(np.shape(summary_1d)[0]):\r\n",
        "            \r\n",
        "            if summary_1d[m]:\r\n",
        "              f = getattr(np, repr_1d_summary[m])  # która statystyka wybrana repr_1d_summary = ['min', 'max', 'mean', 'std']\r\n",
        "              paramsy_mir = [f(param_0), f(param_1), f(param_2), f(param_3), f(param_4), f(skosnosc), f(kurtoza), f(plaskosc)]\r\n",
        "              paramsy_mir.extend(f(mfccs, axis = 1).tolist())\r\n",
        "              paramsy_mir.extend(f(mfcc_delta, axis = 1).tolist())\r\n",
        "              paramsy_mir.extend([f(zcr)])\r\n",
        "              paramsy_mir.extend(f(contrast, axis = 1).tolist())\r\n",
        "              paramsy_mir.extend([f(rolloff), f(rms), f(spectral_flux)])\r\n",
        "              paramsy[idx]= paramsy_mir\r\n",
        "              idx += 1\r\n",
        "\r\n",
        "          repr[num] = paramsy\r\n",
        "        \r\n",
        "        if representation_type=='8_classic':\r\n",
        "\r\n",
        "          paramsy = [[[] for _ in range(8)] for _ in range(nb_summary)]\r\n",
        "          idx = 0\r\n",
        "\r\n",
        "          for m in range(np.shape(summary_1d)[0]):\r\n",
        "            \r\n",
        "            if summary_1d[m]:\r\n",
        "              f = getattr(np, repr_1d_summary[m])\r\n",
        "              paramsy[idx]=[f(param_0), f(param_1), f(param_2), f(param_3), f(param_4), f(skosnosc), f(kurtoza), f(plaskosc)]\r\n",
        "              idx += 1\r\n",
        "\r\n",
        "          repr[num] = paramsy\r\n",
        "\r\n",
        "    repr_full[k] = repr\r\n",
        "    print(k,'-', file_names_train_set[k], '- chunks:', np.shape(ind_for_train_set[k])[0], '- time:', time.time()-start_time)\r\n",
        "\r\n",
        "  return [file_names_train_set , ind_for_train_set, info_chunksy, representation_type, repr_full]     \r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}