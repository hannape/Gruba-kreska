{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. Wczytanie_danych.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZYjwXzmDcsGkz8ZnAULZ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hannape/Gruba-kreska/blob/main/2_Wczytanie_danych.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKFQrzjGsl8N"
      },
      "source": [
        "Będzie to funkcja która pozwoli wczytać dane z pliku wav, podzieli je na M-ms klipy (500 ms domyślne) z N-sek overlapem (150 ms), wczyta etykiety z pliku txt (jeśli więcej niż 4ms głosu w próbce - to pozytywna), stworzy wektory \n",
        "\n",
        "* X_train i Y_train\n",
        "* X_valid i Y_valid\n",
        "\n",
        "W sumie mam 94 nagrania. \n",
        "\n",
        "* treningowy - 88 nagrań, balansujemy, jeśli są dostępne inne etykiety niż interesujących nas głosów (np gh, t, g), to dodajemy je jako próbki negatywne. Jeśłi nie ma głosów w nagraniu to bierzemy P (50) próbek losowych z tego nagrania. \n",
        "* walidacyjny to 8 nagrań, które balansujemy tylko trochę - np z poziomu 1:100, do poziomu 1:10.\n",
        "\n",
        "\n",
        "\n",
        "**Ale najpierw, trzeba jakoś wybrać te nagrania do walida. trzeba sprawdzić stosunki s : k głównie, może jakoś uwzględnić d i r, choć ich dużo mniej, więc z inną wagą**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwdJB9sPsfM4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ea7312-09ee-42b2-b5a1-eac81931ecce"
      },
      "source": [
        "# Wczytywanie google drive'a\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from __future__ import print_function"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DndhmZEerl4"
      },
      "source": [
        "import os\n",
        "import contextlib\n",
        "import numpy as np\n",
        "import wave\n",
        "import math\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b04WgWNxetjQ"
      },
      "source": [
        "# Parametry które będą wchodzić do funkcji\n",
        "\n",
        "path_test1618_txt = 'drive/My Drive/poprawione etykiety 24112020/testowe/'\n",
        "path_train161718_txt =  'drive/My Drive/poprawione etykiety 24112020/treningowe/'\n",
        "path_test1618_wav = 'drive/My Drive/testowe_1618/'\n",
        "path_train161718_wav =  'drive/My Drive/treningowe94_161718/'\n",
        "  \n",
        "balance_types = ['full_rec','balanced', 'valid' ]  # na potrzeby treningu, valida, testu\n",
        "balance_ratios = [None, [50, 25], [400, 100]]\n",
        "chunk_length_ms = 500 # 500 ms\n",
        "chunk_overlap = 150 # 150 ms\n",
        "calls_0 = ['t', 'g', 'czapla', 'gh', 'puszczyk']                                    # etykiety które są negatywne\n",
        "calls_1 = ['d', 'd?', 'k', 'k?', 'kwiczol', 'r','r?', 's', 's?', 'skowronek', 'ni'] # calls of interest\n",
        "calls_unknown = ['???','??? mysz', '??? high freq']                                 # unknown, nie wiem czy to głos czy nie, więc będę wyrzucać te chunksy to zawierające\n",
        "tolerance = 0.004                                                                   # jaka tolerancja, w sek (jeśli mniej niż ta wartość znajdzie się w chunksie, to uznajemy że głosu tam nie ma)\n",
        "valid_set = ['9niski_szum_BUK4_20161025_000604', 'BUK5_20180930_000704', 'BUK4_20161024_223604', 'BUK4_20171001_020404a', 'BUK1_20160914_011604', 'BUK5_20170910_025605', 'BUK4_20161013_200104', 'BUK5_20181003_235705']\n",
        "test_rec_to_cut = ['BUK5_20161101_002104a', 'BUK5_20161101_002104b']  # nagrania do wyrzucenia ze starego zbioru testowego"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f5ujDUmeuLQ"
      },
      "source": [
        "def my_read_labels(label_name,path_txt):  # ta sama funkcja co w 1. poprawianie danych\n",
        "    '''Wczytuje etykiety czasowe z pliku labels.txt w folderze train.\n",
        "    \n",
        "    Returns:\n",
        "        ndarray: Tablica z etykietami czasowymi zawierająca kolumny:  sekunda początku dźwięku, sekunda końca dźwięku, gatunek.\n",
        "    '''\n",
        "    labels = []\n",
        "    with open(os.path.join(path_txt, label_name + '.txt'), 'r') as file:\n",
        "        text = file.read()\n",
        "        for line in text.split('\\n')[0:]:\n",
        "            if len(line) > 1:\n",
        "                start, stop, spec = line.split('\\t')\n",
        "                #print(start)\n",
        "                start, stop, spec = float(start), float(stop), str(spec),\n",
        "                labels.append([start, stop, spec])\n",
        "    return np.array(labels)\n",
        "\n",
        "\n",
        "def my_check_labels(second, chunk_length_s, labels, tol=0.):\n",
        "    '''Sprawdza czy w ramce czasowej [second, second + chunk_length_s] znajduje się coś wg etykiet `labels`.\n",
        "    \n",
        "    Args:\n",
        "        second (float): Sekunda nagrania.\n",
        "        labels (ndarray): Tablica z etykietami, której 1 kolumna oznacza początek, a 2ga - koniec nagrania.\n",
        "        tol (float): Tolerancja na brzegach fragmentu. Dźwięk, żeby był uznany, musi się kończyć po czasie `second+tol`\n",
        "            lub zaczynać przed czasem `second+chunk_length-tol`.\n",
        "    Returns:\n",
        "        bool: Czy w ramce czasowej jest etykieta - co najmniej 4 ms labelu.\n",
        " ''' \n",
        "\n",
        "  # jeśli początek etykiety zawiera się w chunku, najpóźniej 4ms przed końcem chunka\n",
        "  # jeśli koniec etykiety zawiera się w chunku, i najwcześniej 4 ms po rozpoczęciu chunka\n",
        "  # jeśli początek etykiety zaczyna się rpzed, a koniec po (w przypadku głosów dłuższych niż chunk length, b. rzadkie przypadki dla 0.5 sek)\n",
        "    return (float(labels[0]) >= second and float(labels[0]) < second + chunk_length_s - tol) or \\\n",
        "           (float(labels[1]) < second + chunk_length_s and float(labels[1]) > second + tol) or \\\n",
        "           (float(labels[0]) < second and float(labels[1]) > second + chunk_length_s)              \n",
        "           #and (labels[2] in calls_to_cut)    # nie sprawdzajmy tu jaka to etykieta jest\n",
        "\n",
        "def my_map_seconds_to_y(labels, recording_duration, calls_of_interest, calls_to_cut, calls_unknown):  ## Chcemy 500 ms z 150 ms overlapem\n",
        "    '''Tworzy etykiety dla każdego kolejnego chunksa. 1 gdy co najmniej 4 ms etykiety się znajdują w chunksie (gdy urwane dźwięki na brzegach, <4ms - to 0).\n",
        "    \n",
        "    Args:\n",
        "        labels (ndarray): Tablica z etykietami, której 1 kolumna oznacza początek, a druga - koniec nagrania.\n",
        "    Returns:\n",
        "        ndarray: Tablica z binarnymi etykietami.\n",
        "    '''\n",
        "    #STARE: calls_to_cut = ['t', 't?', 't ','t  ', 'g', 'czapla', 'gh', 'g cz', 'puszczyk','gaski','g?','mewa?','zwierzak?','high freq','g niskie','??? mysz']\n",
        "    \n",
        "    \n",
        "    duration_in_ms = recording_duration*1000\n",
        "    nr_of_chunks =  1 + (duration_in_ms - chunk_length_ms) / (chunk_length_ms - chunk_overlap)\n",
        "    print(\"ilość chunksów w tym nagraniu: \", math.ceil(nr_of_chunks) )\n",
        "    \n",
        "    \n",
        "    y = [0] * math.ceil(nr_of_chunks)             # recording_duration \n",
        "    y_restrictive = [0] * math.ceil(nr_of_chunks) # recording_duration\n",
        "    chunks_start, chunks_end = [0] * math.ceil(nr_of_chunks), [0] * math.ceil(nr_of_chunks)      \n",
        "    has_unknown, has_noise = [0] * math.ceil(nr_of_chunks), [0] * math.ceil(nr_of_chunks)\n",
        "    call_id = [[] for _ in range(math.ceil(nr_of_chunks))]\n",
        "    chunks_species = [[] for _ in range(math.ceil(nr_of_chunks))]\n",
        "    \n",
        "    print(np.shape(labels))\n",
        "    for s in range(math.ceil(nr_of_chunks)):\n",
        "        chunks_start[s] = s * ((chunk_length_ms-chunk_overlap) / 1000)  # czyli s * 0.35\n",
        "        chunks_end[s] = chunks_start[s] + chunk_length_ms/1000 \n",
        "        for ind,l in enumerate(labels):\n",
        "            #print('label_index: ',ind, ' a label to: ', l[2] )\n",
        "            if my_check_labels(chunks_start[s], chunk_length_ms/1000, l):\n",
        "                #print(s*0.35)\n",
        "                if l[2] in calls_to_cut:\n",
        "                  has_noise[s] = 1\n",
        "                if l[2] in calls_unknown:\n",
        "                  has_unknown[s] = 1\n",
        "                if l[2] in calls_of_interest:  \n",
        "                  y[s] = 1 \n",
        " \n",
        "            if my_check_labels(chunks_start[s], chunk_length_ms/1000, l, 0.004): #z tolerancją \n",
        "                \n",
        "                if l[2] in calls_to_cut:\n",
        "                  chunks_species[s].append(l[2])\n",
        "                if l[2] in calls_unknown:\n",
        "                  has_unknown[s] = 1\n",
        "                  chunks_species[s].append(l[2])\n",
        "                if l[2] in calls_of_interest:  \n",
        "                  y_restrictive[s] = 1  \n",
        "                  chunks_species[s].append(l[2])  \n",
        "                  call_id[s].append(ind)\n",
        "              \n",
        "                      \n",
        "        if y[s] != y_restrictive[s] and l[2] in calls_of_interest:\n",
        "            print('próbka ', s, 'zaczynajaca sie ', chunks_start[s],', jest unknown, bo za mały fragment głosu nas interesującego')\n",
        "            #print('y[s]:', y[s],'yres:', y_restrictive[s] )\n",
        "            y[s] = 0    # jeśli mniej niż 4 ms fragment, to zakładamy że nie ma głosu, i dajemy unknown także, by nie karać za ewentualne znalezienie tego głosu\n",
        "            has_unknown[s] = 1\n",
        "    print('Rozmiar ',np.shape([s, chunks_start, chunks_end, y, chunks_species, call_id, has_unknown]))\n",
        "    return s+1, chunks_start, chunks_end, y, chunks_species, call_id, has_unknown, has_noise    \n",
        "\n",
        "\n",
        "def my_load_wav(path_wav, path_txt, recordings_incl = None, recordings_excl = None):   # dłuższa funkcja niż w 1.\n",
        "\n",
        "  recording_labels_all = []\n",
        "  in_which_recording = []\n",
        "  file_names = []\n",
        "\n",
        "  # wszystkie nagrania\n",
        "  if recordings_incl == None and recordings_excl == None:                                        \n",
        "    rec_files = [file_name for file_name in os.listdir(path_wav) if file_name.endswith('.wav')]\n",
        "\n",
        "  # nagrania tylko te w podanym zbiorze (walid)\n",
        "  if recordings_incl != None:                                                                     \n",
        "    rec_files_all = [file_name for file_name in os.listdir(path_wav) if file_name.endswith('.wav')]\n",
        "    recordings_incl = [s + '.wav' for s in recordings_incl]\n",
        "    rec_files = list( set.intersection(set(rec_files_all), set(recordings_incl)))\n",
        "\n",
        "  # nagrania oprócz nagrań w podanym zbiorze (train)  \n",
        "  if recordings_excl != None:                                                                     \n",
        "    rec_files_all = [file_name for file_name in os.listdir(path_wav) if file_name.endswith('.wav')]\n",
        "    recordings_excl = [s + '.wav' for s in recordings_excl]\n",
        "    rec_files = list(set(rec_files_all) - set(recordings_excl))  \n",
        " \n",
        "  print(np.shape(rec_files))\n",
        "  print((rec_files))\n",
        "  #print((rec_files))\n",
        "  #print(np.size(rec_files))\n",
        "\n",
        "  X_matrix = [[] for _ in range(np.size(rec_files))]\n",
        "  file_names = [[] for _ in range(np.size(rec_files))]\n",
        "\n",
        "  for ind, file_name in enumerate(rec_files):\n",
        "      \n",
        "      print(\"------------Analiza nagrania: \" + file_name + \"-----------\")\n",
        "      recording_id = str(file_name.split('.')[0])\n",
        "      \n",
        "      fname = path_wav + file_name      #print(fname)\n",
        "      with contextlib.closing(wave.open(fname,'r')) as f:\n",
        "          frames = f.getnframes()\n",
        "          rate = f.getframerate()\n",
        "          duration = frames / float(rate)\n",
        "          recording_duration = math.ceil(duration)\n",
        "          print(\"Czas trwania nagrania - w sekundach: \" + str(recording_duration))\n",
        "          #print(\"rate:\", rate)\n",
        "    \n",
        "      recording_id = (file_name.split('.')[0])       #print(recording_id)\n",
        "      recording_labels = my_read_labels(recording_id, path_txt)    \n",
        "\n",
        "      print(\"Duration:\", duration)\n",
        "      #y_binary = my_map_seconds_to_y(recording_labels, duration)\n",
        "      chunk_id, chunk_start, chunk_end, has_bird, chunks_species, call_id, has_unknown, has_noise  = my_map_seconds_to_y(recording_labels, duration, calls_1, calls_0, calls_unknown)\n",
        "      chunk_ids = range(chunk_id)\n",
        "      chunk_start = rate*np.array(chunk_start)\n",
        "      chunk_start = [round(num) for num in chunk_start]\n",
        "      chunk_end = rate*np.array(chunk_end)\n",
        "      chunk_end = [round(num) for num in chunk_end]\n",
        "      X_matrix[ind] = [chunk_ids, chunk_start, chunk_end, has_bird, chunks_species, call_id, has_unknown, has_noise]  # !!!! chunk start i end przerzucone na sample !!!!!\n",
        "      file_names[ind] = file_name\n",
        "\n",
        "  return X_matrix , file_names #chunk_id, chunk_start, chunk_end, has_bird, chunks_species, call_id, has_unknown\n",
        "\n",
        "def find_ratio(recordings_names, path_txt):\n",
        "  count_s,count_k, count_d, count_r, count_positives = 0,0,0,0,0\n",
        "  for rec_name in recordings_names:\n",
        "    recording_labels = my_read_labels(rec_name, path_txt)  \n",
        "    #print(recording_labels)\n",
        "    counted_labels = Counter(recording_labels[:,2])\n",
        "\n",
        "    #print(counted_labels)\n",
        "    for calls in labels_s:\n",
        "      count_s += counted_labels[calls]\n",
        "\n",
        "    for calls in labels_k:\n",
        "      count_k += counted_labels[calls]\n",
        "\n",
        "    for calls in labels_d:\n",
        "      count_d += counted_labels[calls]   \n",
        "\n",
        "    for calls in labels_r:\n",
        "      count_r += counted_labels[calls] \n",
        "\n",
        "    for calls in calls_1:\n",
        "      count_positives += counted_labels[calls] \n",
        "\n",
        "  return [count_s, count_k, count_d, count_r, count_positives]  "
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn14hD_8LFxu"
      },
      "source": [
        "#chunk_id, chunk_start, chunk_end, has_bird, chunks_species, call_id, has_unknown = my_load_wav(path_train161718_wav, path_train161718_txt) \n",
        "X_train, file_names_train = my_load_wav(path_train161718_wav, path_train161718_txt, None, valid_set) \n",
        "X_valid, file_names_valid = my_load_wav(path_train161718_wav, path_train161718_txt, valid_set, None) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzxwT3r9SvLz"
      },
      "source": [
        "#print(np.shape(X_train))\n",
        "#czas_trwania_spr= np.array(X_train[0][1])- np.array(X_train[0][2])\n",
        "#print(np.unique(czas_trwania_spr)) # upewnienie się że wszystkie chunki jednakowej długości są\n",
        "\n",
        "columns_dataframe = ['chunk_ids', 'chunk_start', 'chunk_end', 'has_bird', 'chunks_species', 'call_id', 'has_unknown', 'has_noise']\n",
        "\n",
        "result_dataframe_train = pd.DataFrame(data = X_train, index=file_names_train, columns = columns_dataframe)\n",
        "result_dataframe_valid = pd.DataFrame(data = X_valid, index=file_names_valid, columns = columns_dataframe)\n",
        "\n",
        "#print(result_dataframe_train['call_id'][0])\n",
        "#print(result_dataframe_train.loc[ ['BUK5_20181007_001906.wav'] , ['has_unknown', 'has_noise'] ])\n",
        "#file_names_train"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB8MQQk4en_A"
      },
      "source": [
        "**Stworzenie zbalansowanego odpowiednio traina i walida**\n",
        "\n",
        "Więc w trainie, ida wszystkie próbki które mają has_bird = 1 - jako pozytywne\n",
        "\n",
        "Oprócz tego idą te które mają has_noise, has_bird !=1 i has_unknown - obojetenie - jako negatywne\n",
        "\n",
        "Następnie pozbywamy się tych z etykietami unknown - by nie poszły przypadkiem do zbioru, i z pozostałych losujemy randomowo próbki bez głosu. \n",
        "\n",
        "W trainie - tak jak wcześniej może, tyle głosów negatywnych co pozytywnych, ale minimum 50. Jeśli jest wystarczająco tych z labelem noise, to co najmniej 30 (?) próbek wybranych losowo też\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQG1taYKeoI-"
      },
      "source": [
        "import random\n",
        "\n",
        "balance_types = ['full_rec','balanced', 'valid' ]\n",
        "balance_ratios = [None, [50, 25], [400, 100]]  # co najmniej ile próbek negatywnych, w tym ile minimalnie randomów\n",
        "\n",
        "def create_set_ind(result_dataframe, balance, ratios = None):\n",
        "  \n",
        "  print(balance)\n",
        "  file_names = list(result_dataframe.index)\n",
        "  print(len(file_names))\n",
        "  ind_chosen = [[] for _ in range(len(file_names))]\n",
        "  neg_random_numb = 0;\n",
        "  all_pos = 0\n",
        "  all_chunks = 0\n",
        "\n",
        "\n",
        "  for file_i, file_name in enumerate(file_names):\n",
        "    print(file_i, ' nagranie ', file_name)\n",
        "    \n",
        "    indices_hasbird = [i for i, j in enumerate(result_dataframe['has_bird'][file_i]) if j == 1]\n",
        "    indices_hasnoise = [i for i, j in enumerate(result_dataframe['has_noise'][file_i]) if j == 1]\n",
        "    indices_unknown = [i for i, j in enumerate(result_dataframe['has_unknown'][file_i]) if j == 1]\n",
        "    indices_all = result_dataframe['chunk_ids'][file_i]\n",
        "    pos = indices_hasbird\n",
        "\n",
        "\n",
        "    if balance == 'full_rec':\n",
        "      \n",
        "      ind_chosen[file_i] = list(set(indices_all) - (set(indices_unknown) - set(indices_hasbird)) )  \n",
        "      # te które mają ptaka i unknown, to zostają. W każdym innym przypadku, unknown wylatuje z setu\n",
        "      #print(np.shape(ind_chosen))\n",
        "      all_pos += len(pos)\n",
        "      all_chunks += len(ind_chosen[file_i])\n",
        "      print('pos: ', len(indices_hasbird))  # pozytywne\n",
        "      neg_labels = list(set(indices_hasnoise) - set(indices_hasbird +indices_unknown))\n",
        "      print('neg hałas:' , len(neg_labels))\n",
        "      print('ind_chosen:' , len(ind_chosen[file_i]))\n",
        "\n",
        "    if balance == 'balanced' or balance == 'valid':\n",
        "      \n",
        "      print('pos: ', len(indices_hasbird))  # pozytywne\n",
        "      \n",
        "      neg_labels = list(set(indices_hasnoise) - set(indices_hasbird +indices_unknown))\n",
        "      print('neg hałas:' , len(neg_labels))\n",
        "      #print(len(list(set(indices_hasnoise) - set(indices_hasbird +indices_unknown)))) # z samym hałasem, bez unknown czy ptaków. Czyli 0\n",
        "      #temp =  list(set(indices_hasbird + indices_hasnoise))\n",
        "\n",
        "      \n",
        "      \n",
        "      if (len(pos) - len(neg_labels)>=0):   \n",
        "        neg_random_numb = len(pos) - len(neg_labels)\n",
        "        if (neg_random_numb < ratios[1]):\n",
        "          neg_random_numb = ratios[1]\n",
        "        if neg_random_numb + len(neg_labels) < ratios[0]:\n",
        "          neg_random_numb = ratios[0] - len(neg_labels)\n",
        "      else:\n",
        "        neg_random_numb = ratios[1]\n",
        "\n",
        "      print('neg random: ', neg_random_numb)\n",
        "\n",
        "      neg_random_set = list(set(indices_all) - (set(indices_unknown + indices_hasbird + indices_hasnoise)))\n",
        "\n",
        "\n",
        "      random.seed(file_i)\n",
        "      neg_random = random.sample(neg_random_set, neg_random_numb)\n",
        "      print(neg_random[0:5])\n",
        "      ind_chosen[file_i] = sorted(list(set(indices_hasbird + neg_labels + neg_random)))\n",
        "\n",
        "      all_pos += len(pos)\n",
        "      all_chunks += len(ind_chosen[file_i])  \n",
        "\n",
        "  print('wszystkich chunków: ', all_chunks,', w tym ', all_pos, ' pozytywnych. Czyli ', 100* round(all_pos/all_chunks,4),' % pozytywnych w zbiorze', balance )\n",
        "  return file_names, ind_chosen\n"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkpMY1HLAe1U",
        "outputId": "d4239a59-8d24-46a1-99f2-fcc186ac8b49"
      },
      "source": [
        "file_names_train_set, ind_for_train_set = create_set_ind(result_dataframe_train, balance_types[1], balance_ratios[1])\n",
        "file_names_valid_set, ind_for_valid_set = create_set_ind(result_dataframe_valid, balance_types[2], balance_ratios[2])"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "balanced\n",
            "86\n",
            "0  nagranie  BUK5_20181007_001906.wav\n",
            "pos:  196\n",
            "neg hałas: 14\n",
            "neg random:  182\n",
            "[3285, 3578, 344, 2183, 4375]\n",
            "1  nagranie  BUK4_20161002_235805.wav\n",
            "pos:  64\n",
            "neg hałas: 28\n",
            "neg random:  36\n",
            "[1125, 4746, 524, 2125, 988]\n",
            "2  nagranie  BUK4_20161104_041504.wav\n",
            "pos:  12\n",
            "neg hałas: 27\n",
            "neg random:  25\n",
            "[468, 755, 700, 2975, 1395]\n",
            "3  nagranie  BUK4_20171022_004304a.wav\n",
            "pos:  119\n",
            "neg hałas: 17\n",
            "neg random:  102\n",
            "[1996, 4986, 4567, 1093, 3101]\n",
            "4  nagranie  BUK4_20160926_004604.wav\n",
            "pos:  115\n",
            "neg hałas: 9\n",
            "neg random:  106\n",
            "[1989, 2550, 860, 3327, 4018]\n",
            "5  nagranie  BUK5_20170920_013105b.wav\n",
            "pos:  36\n",
            "neg hałas: 35\n",
            "neg random:  25\n",
            "[2115, 2978, 4413, 239, 3872]\n",
            "6  nagranie  BUK4_20161104_034504.wav\n",
            "pos:  2\n",
            "neg hałas: 17\n",
            "neg random:  25\n",
            "[4719, 663, 3987, 2150, 303]\n",
            "7  nagranie  BUK5_20171007_031905.wav\n",
            "pos:  119\n",
            "neg hałas: 34\n",
            "neg random:  85\n",
            "[2702, 1251, 3316, 397, 596]\n",
            "8  nagranie  BUK4_20160925_191604.wav\n",
            "pos:  33\n",
            "neg hałas: 35\n",
            "neg random:  25\n",
            "[1865, 3064, 3105, 1038, 1590]\n",
            "9  nagranie  BUK4_20160919_013304.wav\n",
            "pos:  53\n",
            "neg hałas: 10\n",
            "neg random:  43\n",
            "[3841, 5089, 3106, 2222, 1150]\n",
            "10  nagranie  BUK4_20160925_214604.wav\n",
            "pos:  46\n",
            "neg hałas: 19\n",
            "neg random:  31\n",
            "[4741, 271, 3563, 4003, 4796]\n",
            "11  nagranie  BUK5_20181006_204906.wav\n",
            "pos:  94\n",
            "neg hałas: 33\n",
            "neg random:  61\n",
            "[3818, 4723, 3941, 3814, 4292]\n",
            "12  nagranie  1swierszcze_nakladki_BUK4_20160925_204604.wav\n",
            "pos:  131\n",
            "neg hałas: 19\n",
            "neg random:  112\n",
            "[4022, 2272, 4476, 2956, 1211]\n",
            "13  nagranie  BUK5_20171026_010405.wav\n",
            "pos:  0\n",
            "neg hałas: 17\n",
            "neg random:  25\n",
            "[2129, 2391, 1528, 1896, 1210]\n",
            "14  nagranie  BUK4_20161005_012304.wav\n",
            "pos:  16\n",
            "neg hałas: 39\n",
            "neg random:  25\n",
            "[891, 5115, 4384, 2056, 2261]\n",
            "15  nagranie  BUK5_20181007_014905.wav\n",
            "pos:  67\n",
            "neg hałas: 28\n",
            "neg random:  39\n",
            "[1745, 95, 4344, 302, 1318]\n",
            "16  nagranie  BUK4_20161019_011904.wav\n",
            "pos:  21\n",
            "neg hałas: 16\n",
            "neg random:  34\n",
            "[2995, 3879, 3972, 2361, 3451]\n",
            "17  nagranie  BUK4_20161103_204504.wav\n",
            "pos:  19\n",
            "neg hałas: 31\n",
            "neg random:  25\n",
            "[4322, 3410, 2498, 3010, 2385]\n",
            "18  nagranie  BUK5_20170906_023604.wav\n",
            "pos:  0\n",
            "neg hałas: 12\n",
            "neg random:  25\n",
            "[1490, 1012, 3686, 2750, 1969]\n",
            "19  nagranie  BUK5_20181006_201906.wav\n",
            "pos:  93\n",
            "neg hałas: 47\n",
            "neg random:  46\n",
            "[363, 4366, 1002, 4293, 1668]\n",
            "20  nagranie  BUK5_20181006_214905.wav\n",
            "pos:  151\n",
            "neg hałas: 33\n",
            "neg random:  118\n",
            "[1290, 2212, 868, 2784, 4871]\n",
            "21  nagranie  BUK5_20181007_031905.wav\n",
            "pos:  93\n",
            "neg hałas: 29\n",
            "neg random:  64\n",
            "[1386, 3510, 2371, 4028, 1814]\n",
            "22  nagranie  BUK5_20181007_234705.wav\n",
            "pos:  37\n",
            "neg hałas: 23\n",
            "neg random:  27\n",
            "[1170, 2011, 201, 5081, 3700]\n",
            "23  nagranie  BUK5_20181006_231905.wav\n",
            "pos:  110\n",
            "neg hałas: 26\n",
            "neg random:  84\n",
            "[2482, 729, 152, 4995, 2620]\n",
            "24  nagranie  BUK4_20161104_051504.wav\n",
            "pos:  4\n",
            "neg hałas: 22\n",
            "neg random:  25\n",
            "[3153, 4799, 1503, 1798, 1376]\n",
            "25  nagranie  BUK4_20160925_194604.wav\n",
            "pos:  54\n",
            "neg hałas: 91\n",
            "neg random:  25\n",
            "[3148, 125, 1784, 2540, 3959]\n",
            "26  nagranie  BUK5_20181007_021905.wav\n",
            "pos:  78\n",
            "neg hałas: 38\n",
            "neg random:  40\n",
            "[1693, 1714, 3618, 5034, 4552]\n",
            "27  nagranie  BUK5_20181006_234905.wav\n",
            "pos:  65\n",
            "neg hałas: 33\n",
            "neg random:  32\n",
            "[4013, 2307, 2379, 1634, 615]\n",
            "28  nagranie  BUK5_20181007_041905.wav\n",
            "pos:  215\n",
            "neg hałas: 38\n",
            "neg random:  177\n",
            "[946, 1104, 4700, 1509, 1919]\n",
            "29  nagranie  BUK4_20161104_004504.wav\n",
            "pos:  7\n",
            "neg hałas: 20\n",
            "neg random:  25\n",
            "[4513, 627, 2848, 4930, 4989]\n",
            "30  nagranie  BUK5_20181007_004906.wav\n",
            "pos:  159\n",
            "neg hałas: 15\n",
            "neg random:  144\n",
            "[4569, 2477, 263, 1805, 2208]\n",
            "31  nagranie  BUK5_20181006_194905.wav\n",
            "pos:  129\n",
            "neg hałas: 59\n",
            "neg random:  70\n",
            "[103, 4010, 949, 3349, 1204]\n",
            "32  nagranie  BUK5_20181009_001405.wav\n",
            "pos:  58\n",
            "neg hałas: 103\n",
            "neg random:  25\n",
            "[656, 1814, 1241, 2578, 2015]\n",
            "33  nagranie  6wichura_deszcz_BUK4_20161005_022304.wav\n",
            "pos:  8\n",
            "neg hałas: 21\n",
            "neg random:  25\n",
            "[4701, 1374, 1914, 2275, 3950]\n",
            "34  nagranie  BUK5_20181006_211905.wav\n",
            "pos:  140\n",
            "neg hałas: 39\n",
            "neg random:  101\n",
            "[4495, 2999, 4976, 229, 1913]\n",
            "35  nagranie  BUK4_20161104_014504.wav\n",
            "pos:  0\n",
            "neg hałas: 7\n",
            "neg random:  25\n",
            "[4501, 2754, 1083, 2796, 1267]\n",
            "36  nagranie  BUK4_20161031_232104b.wav\n",
            "pos:  621\n",
            "neg hałas: 163\n",
            "neg random:  458\n",
            "[3178, 558, 197, 2767, 730]\n",
            "37  nagranie  5szum_sredni_nakladki_BUK4_20161011_000804.wav\n",
            "pos:  135\n",
            "neg hałas: 26\n",
            "neg random:  109\n",
            "[773, 4350, 296, 3122, 3689]\n",
            "38  nagranie  BUK4_20161104_044504.wav\n",
            "pos:  0\n",
            "neg hałas: 25\n",
            "neg random:  25\n",
            "[3470, 3535, 838, 546, 3019]\n",
            "39  nagranie  BUK4_20161104_031504.wav\n",
            "pos:  7\n",
            "neg hałas: 23\n",
            "neg random:  25\n",
            "[1723, 2131, 3163, 212, 1601]\n",
            "40  nagranie  BUK5_20170923_025405.wav\n",
            "pos:  178\n",
            "neg hałas: 34\n",
            "neg random:  144\n",
            "[3915, 4954, 4475, 273, 2094]\n",
            "41  nagranie  BUK4_20160925_201604.wav\n",
            "pos:  113\n",
            "neg hałas: 86\n",
            "neg random:  27\n",
            "[3237, 2826, 1976, 1422, 3275]\n",
            "42  nagranie  2koniec_swierszczy_BUK4_20160925_221604.wav\n",
            "pos:  66\n",
            "neg hałas: 3\n",
            "neg random:  63\n",
            "[917, 205, 2287, 2025, 1845]\n",
            "43  nagranie  BUK4_20181029_235604.wav\n",
            "pos:  18\n",
            "neg hałas: 51\n",
            "neg random:  25\n",
            "[323, 2383, 1219, 3850, 3080]\n",
            "44  nagranie  BUK5_20181002_235905.wav\n",
            "pos:  5\n",
            "neg hałas: 20\n",
            "neg random:  25\n",
            "[3358, 4282, 4461, 958, 1452]\n",
            "45  nagranie  BUK4_20160925_231604.wav\n",
            "pos:  77\n",
            "neg hałas: 6\n",
            "neg random:  71\n",
            "[2267, 3474, 4071, 2150, 677]\n",
            "46  nagranie  BUK5_20181004_212404a.wav\n",
            "pos:  20\n",
            "neg hałas: 42\n",
            "neg random:  25\n",
            "[629, 3331, 331, 4899, 4885]\n",
            "47  nagranie  BUK4_20160926_024604.wav\n",
            "pos:  218\n",
            "neg hałas: 7\n",
            "neg random:  211\n",
            "[3021, 539, 3695, 4745, 3894]\n",
            "48  nagranie  BUK5_20171007_024907b.wav\n",
            "pos:  13\n",
            "neg hałas: 16\n",
            "neg random:  25\n",
            "[4520, 2602, 1094, 4592, 4410]\n",
            "49  nagranie  BUK4_20161104_054506.wav\n",
            "pos:  0\n",
            "neg hałas: 14\n",
            "neg random:  25\n",
            "[549, 2828, 3396, 907, 2658]\n",
            "50  nagranie  BUK5_20170904_233905.wav\n",
            "pos:  5\n",
            "neg hałas: 26\n",
            "neg random:  25\n",
            "[4099, 2198, 3002, 2001, 3900]\n",
            "51  nagranie  BUK4_20161103_181504.wav\n",
            "pos:  0\n",
            "neg hałas: 21\n",
            "neg random:  25\n",
            "[2012, 4133, 4543, 1342, 2033]\n",
            "52  nagranie  7wiatr_BUK4_20161006_002104.wav\n",
            "pos:  4\n",
            "neg hałas: 8\n",
            "neg random:  25\n",
            "[2204, 448, 4209, 3973, 3047]\n",
            "53  nagranie  BUK4_20161104_021504.wav\n",
            "pos:  4\n",
            "neg hałas: 1\n",
            "neg random:  49\n",
            "[5060, 1769, 3744, 4117, 3959]\n",
            "54  nagranie  BUK4_20160918_223304.wav\n",
            "pos:  22\n",
            "neg hałas: 10\n",
            "neg random:  40\n",
            "[1137, 3625, 4597, 2461, 3993]\n",
            "55  nagranie  BUK5_20181007_011905.wav\n",
            "pos:  118\n",
            "neg hałas: 16\n",
            "neg random:  102\n",
            "[769, 1655, 1265, 2542, 672]\n",
            "56  nagranie  BUK4_20161031_232104a.wav\n",
            "pos:  353\n",
            "neg hałas: 65\n",
            "neg random:  288\n",
            "[5011, 109, 4209, 4649, 2694]\n",
            "57  nagranie  BUK5_20181007_034905.wav\n",
            "pos:  75\n",
            "neg hałas: 22\n",
            "neg random:  53\n",
            "[355, 3081, 4929, 5057, 158]\n",
            "58  nagranie  BUK4_20160926_014604.wav\n",
            "pos:  220\n",
            "neg hałas: 11\n",
            "neg random:  209\n",
            "[4986, 1673, 1752, 1709, 350]\n",
            "59  nagranie  BUK5_20181007_044905.wav\n",
            "pos:  688\n",
            "neg hałas: 126\n",
            "neg random:  562\n",
            "[2086, 755, 4364, 202, 1225]\n",
            "60  nagranie  4szum_sredni_BUK4_20160918_013604.wav\n",
            "pos:  14\n",
            "neg hałas: 5\n",
            "neg random:  45\n",
            "[2539, 2339, 4754, 1278, 2192]\n",
            "61  nagranie  BUK4_20160926_034604.wav\n",
            "pos:  220\n",
            "neg hałas: 22\n",
            "neg random:  198\n",
            "[4252, 1548, 4786, 1855, 2762]\n",
            "62  nagranie  BUK4_20161022_224004.wav\n",
            "pos:  8\n",
            "neg hałas: 31\n",
            "neg random:  25\n",
            "[4751, 1430, 540, 1967, 3842]\n",
            "63  nagranie  BUK4_20160926_031604.wav\n",
            "pos:  233\n",
            "neg hałas: 26\n",
            "neg random:  207\n",
            "[3834, 3825, 2530, 2159, 4183]\n",
            "64  nagranie  BUK4_20160925_211604.wav\n",
            "pos:  70\n",
            "neg hałas: 26\n",
            "neg random:  44\n",
            "[3989, 1048, 5118, 3380, 4487]\n",
            "65  nagranie  BUK4_20161103_234504.wav\n",
            "pos:  4\n",
            "neg hałas: 23\n",
            "neg random:  25\n",
            "[3419, 2388, 2378, 4239, 1811]\n",
            "66  nagranie  BUK4_20161104_011504.wav\n",
            "pos:  7\n",
            "neg hałas: 21\n",
            "neg random:  25\n",
            "[581, 2576, 3585, 2026, 3676]\n",
            "67  nagranie  BUK4_20161104_011504b1110_1230.wav\n",
            "pos:  2\n",
            "neg hałas: 6\n",
            "neg random:  25\n",
            "[21, 31, 204, 108, 123]\n",
            "68  nagranie  BUK4_20161104_024504.wav\n",
            "pos:  2\n",
            "neg hałas: 9\n",
            "neg random:  25\n",
            "[3832, 4114, 913, 4983, 4762]\n",
            "69  nagranie  BUK4_20160925_234604.wav\n",
            "pos:  118\n",
            "neg hałas: 18\n",
            "neg random:  100\n",
            "[313, 796, 1395, 557, 5095]\n",
            "70  nagranie  BUK5_20181006_191905.wav\n",
            "pos:  61\n",
            "neg hałas: 64\n",
            "neg random:  25\n",
            "[998, 2479, 3853, 3775, 1153]\n",
            "71  nagranie  BUK5_20170902_234404.wav\n",
            "pos:  15\n",
            "neg hałas: 14\n",
            "neg random:  36\n",
            "[2658, 4188, 5112, 71, 2176]\n",
            "72  nagranie  BUK5_20181002_000206.wav\n",
            "pos:  6\n",
            "neg hałas: 35\n",
            "neg random:  25\n",
            "[606, 4915, 1545, 2843, 4499]\n",
            "73  nagranie  BUK5_20171102_045004b.wav\n",
            "pos:  8\n",
            "neg hałas: 19\n",
            "neg random:  25\n",
            "[2321, 1028, 4146, 3966, 4654]\n",
            "74  nagranie  BUK5_20181006_221905.wav\n",
            "pos:  90\n",
            "neg hałas: 43\n",
            "neg random:  47\n",
            "[4342, 941, 2670, 999, 2583]\n",
            "75  nagranie  BUK4_20160926_011604.wav\n",
            "pos:  156\n",
            "neg hałas: 16\n",
            "neg random:  140\n",
            "[3849, 4967, 3723, 3880, 350]\n",
            "76  nagranie  BUK5_20170912_015105.wav\n",
            "pos:  1\n",
            "neg hałas: 37\n",
            "neg random:  25\n",
            "[3066, 3832, 3222, 1664, 2463]\n",
            "77  nagranie  BUK4_20160926_001604.wav\n",
            "pos:  70\n",
            "neg hałas: 18\n",
            "neg random:  52\n",
            "[2103, 2710, 1639, 1996, 1605]\n",
            "78  nagranie  3wzgledna_cisza_BUK4_20160925_224604.wav\n",
            "pos:  111\n",
            "neg hałas: 2\n",
            "neg random:  109\n",
            "[1566, 806, 2520, 2158, 3579]\n",
            "79  nagranie  BUK5_20170920_013105a.wav\n",
            "pos:  42\n",
            "neg hałas: 27\n",
            "neg random:  25\n",
            "[1202, 3630, 2906, 4948, 1346]\n",
            "80  nagranie  BUK4_20160926_021604.wav\n",
            "pos:  188\n",
            "neg hałas: 13\n",
            "neg random:  175\n",
            "[2332, 3379, 4635, 3604, 3170]\n",
            "81  nagranie  BUK5_20181006_224905.wav\n",
            "pos:  91\n",
            "neg hałas: 36\n",
            "neg random:  55\n",
            "[4253, 3814, 2842, 4696, 4472]\n",
            "82  nagranie  BUK4_20171017_015504b.wav\n",
            "pos:  89\n",
            "neg hałas: 22\n",
            "neg random:  67\n",
            "[1226, 4106, 4238, 2444, 1514]\n",
            "83  nagranie  8deszczk_bezptasio_BUK4_20161015_235704.wav\n",
            "pos:  2\n",
            "neg hałas: 19\n",
            "neg random:  25\n",
            "[4083, 3786, 738, 1061, 3119]\n",
            "84  nagranie  BUK5_20181001_000405.wav\n",
            "pos:  20\n",
            "neg hałas: 73\n",
            "neg random:  25\n",
            "[2395, 326, 4088, 38, 4355]\n",
            "85  nagranie  BUK5_20181007_024905.wav\n",
            "pos:  66\n",
            "neg hałas: 42\n",
            "neg random:  25\n",
            "[1701, 908, 2703, 1639, 1890]\n",
            "wszystkich chunków:  16091 , w tym  7198  pozytywnych. Czyli  44.73  % pozytywnych w zbiorze balanced\n",
            "valid\n",
            "8\n",
            "0  nagranie  BUK4_20171001_020404a.wav\n",
            "pos:  47\n",
            "neg hałas: 23\n",
            "neg random:  377\n",
            "[3199, 3489, 332, 2150, 4248]\n",
            "1  nagranie  BUK4_20161013_200104.wav\n",
            "pos:  12\n",
            "neg hałas: 103\n",
            "neg random:  100\n",
            "[1110, 4771, 526, 2121, 975]\n",
            "2  nagranie  BUK4_20161024_223604.wav\n",
            "pos:  18\n",
            "neg hałas: 26\n",
            "neg random:  100\n",
            "[465, 753, 698, 2986, 1396]\n",
            "3  nagranie  BUK5_20181003_235705.wav\n",
            "pos:  9\n",
            "neg hałas: 20\n",
            "neg random:  100\n",
            "[1962, 4874, 4477, 1076, 3046]\n",
            "4  nagranie  BUK1_20160914_011604.wav\n",
            "pos:  45\n",
            "neg hałas: 22\n",
            "neg random:  378\n",
            "[1948, 2509, 852, 3284, 3979]\n",
            "5  nagranie  BUK5_20180930_000704.wav\n",
            "pos:  34\n",
            "neg hałas: 49\n",
            "neg random:  100\n",
            "[2128, 2984, 4420, 243, 3881]\n",
            "6  nagranie  BUK5_20170910_025605.wav\n",
            "pos:  3\n",
            "neg hałas: 20\n",
            "neg random:  100\n",
            "[4726, 665, 3993, 2157, 304]\n",
            "7  nagranie  9niski_szum_BUK4_20161025_000604.wav\n",
            "pos:  46\n",
            "neg hałas: 8\n",
            "neg random:  392\n",
            "[2697, 1271, 3284, 397, 597]\n",
            "wszystkich chunków:  2132 , w tym  214  pozytywnych. Czyli  10.040000000000001  % pozytywnych w zbiorze valid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K--7viyA9u1",
        "outputId": "ea419dac-e2f7-4848-fe8d-8cf564332bc9"
      },
      "source": [
        "# sprawdzenie tego w pełnych dataFrame'ach train i walid, czy zsumują się tak samo wartości z kolumny has_bird\n",
        "check_sum_positives = 0\n",
        "\n",
        "for i,file_name_train_set in enumerate(file_names_train_set):\n",
        "  rowData = result_dataframe_train.loc[file_name_train_set]\n",
        "  check_sum_positives += np.array(rowData[\"has_bird\"])[ind_for_train_set[i]].sum()\n",
        "print(check_sum_positives)\n",
        "\n",
        "check_sum_positives = 0\n",
        "for i,file_name_valid_set in enumerate(file_names_valid_set):\n",
        "  rowData = result_dataframe_valid.loc[file_name_valid_set]\n",
        "  check_sum_positives += np.array(rowData[\"has_bird\"])[ind_for_valid_set[i]].sum()\n",
        "\n",
        "print(check_sum_positives)"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7198\n",
            "214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezBabwdXP9Q_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dcf68b0-68df-483f-cdaf-bf5a9cfc52aa"
      },
      "source": [
        "# No i sprawdzenie testu, jaki tam stosunek będzie jeśli wyrzucimy próbki unknown ( i sprawdzic ile ich jest)\n",
        "X_test_new, file_names_test_new = my_load_wav(path_test1618_wav, path_test1618_txt, None, test_rec_to_cut) \n",
        "result_dataframe_test_new = pd.DataFrame(data = X_test_new, index=file_names_test_new, columns = columns_dataframe)\n",
        "\n",
        "X_test_old, file_names_test_old = my_load_wav(path_test1618_wav, path_test1618_txt) \n",
        "result_dataframe_test_old = pd.DataFrame(data = X_test_old, index=file_names_test_old, columns = columns_dataframe)"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tuuu!\n",
            "(18,)\n",
            "['BUK4_20160922_005604.wav', 'BUK4_20180913_201703.wav', 'BUK5_20181021_004605deszczyk.wav', 'BUK4_20161008_004605.wav', 'BUK5_20181010_011205.wav', 'BUK5_20181028_043105.wav', 'BUK1_20181013$023504.wav', 'BUK5_20180921_015906a.wav', 'BUK1_20181011$001004.wav', 'BUK5_20181103_011804.wav', 'BUK4_20161016_035704.wav', 'BUK5_20180909_010005.wav', 'BUK5_20181014_233005.wav', 'BUK5_20180921_015906b.wav', 'BUK5_20181020_014805a.wav', 'BUK1_20180918$040704.wav', 'BUK4_20180925_224703.wav', 'BUK4_20161016_012704.wav']\n",
            "------------Analiza nagrania: BUK4_20160922_005604.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1799\n",
            "Duration: 1798.002358276644\n",
            "ilość chunksów w tym nagraniu:  5137\n",
            "(40, 3)\n",
            "próbka  1461 zaczynajaca sie  511.34999999999997 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK4_20180913_201703.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1800\n",
            "Duration: 1799.0008163265306\n",
            "ilość chunksów w tym nagraniu:  5140\n",
            "(23, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20181021_004605deszczyk.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1798\n",
            "Duration: 1797.0009977324264\n",
            "ilość chunksów w tym nagraniu:  5134\n",
            "(25, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK4_20161008_004605.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1798\n",
            "Duration: 1797.0009977324264\n",
            "ilość chunksów w tym nagraniu:  5134\n",
            "(43, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20181010_011205.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1798\n",
            "Duration: 1797.0009977324264\n",
            "ilość chunksów w tym nagraniu:  5134\n",
            "(41, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20181028_043105.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1798\n",
            "Duration: 1797.0009977324264\n",
            "ilość chunksów w tym nagraniu:  5134\n",
            "(58, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK1_20181013$023504.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1799\n",
            "Duration: 1798.002358276644\n",
            "ilość chunksów w tym nagraniu:  5137\n",
            "(93, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20180921_015906a.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1797\n",
            "Duration: 1796.0025396825397\n",
            "ilość chunksów w tym nagraniu:  5132\n",
            "(57, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK1_20181011$001004.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1799\n",
            "Duration: 1798.002358276644\n",
            "ilość chunksów w tym nagraniu:  5137\n",
            "(169, 3)\n",
            "próbka  173 zaczynajaca sie  60.55 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "próbka  3272 zaczynajaca sie  1145.1999999999998 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "próbka  5043 zaczynajaca sie  1765.05 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20181103_011804.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1799\n",
            "Duration: 1798.002358276644\n",
            "ilość chunksów w tym nagraniu:  5137\n",
            "(49, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK4_20161016_035704.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1799\n",
            "Duration: 1798.002358276644\n",
            "ilość chunksów w tym nagraniu:  5137\n",
            "(28, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20180909_010005.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1798\n",
            "Duration: 1797.0009977324264\n",
            "ilość chunksów w tym nagraniu:  5134\n",
            "(16, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20181014_233005.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1798\n",
            "Duration: 1797.0009977324264\n",
            "ilość chunksów w tym nagraniu:  5134\n",
            "(20, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20180921_015906b.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1797\n",
            "Duration: 1796.0025396825397\n",
            "ilość chunksów w tym nagraniu:  5132\n",
            "(55, 3)\n",
            "próbka  4285 zaczynajaca sie  1499.75 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "próbka  5024 zaczynajaca sie  1758.3999999999999 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20181020_014805a.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1798\n",
            "Duration: 1797.0009977324264\n",
            "ilość chunksów w tym nagraniu:  5134\n",
            "(67, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK1_20180918$040704.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1799\n",
            "Duration: 1798.002358276644\n",
            "ilość chunksów w tym nagraniu:  5137\n",
            "(56, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK4_20180925_224703.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1800\n",
            "Duration: 1799.0008163265306\n",
            "ilość chunksów w tym nagraniu:  5140\n",
            "(26, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK4_20161016_012704.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1799\n",
            "Duration: 1798.002358276644\n",
            "ilość chunksów w tym nagraniu:  5137\n",
            "(6, 3)\n",
            "Rozmiar  (7,)\n",
            "(20,)\n",
            "['BUK4_20160922_005604.wav', 'BUK4_20161016_035704.wav', 'BUK5_20161101_002104b.wav', 'BUK4_20161016_012704.wav', 'BUK4_20161008_004605.wav', 'BUK5_20161101_002104a.wav', 'BUK5_20181020_014805a.wav', 'BUK1_20181013$023504.wav', 'BUK5_20180921_015906b.wav', 'BUK5_20181103_011804.wav', 'BUK5_20181028_043105.wav', 'BUK1_20181011$001004.wav', 'BUK4_20180925_224703.wav', 'BUK5_20180909_010005.wav', 'BUK1_20180918$040704.wav', 'BUK5_20180921_015906a.wav', 'BUK5_20181010_011205.wav', 'BUK4_20180913_201703.wav', 'BUK5_20181014_233005.wav', 'BUK5_20181021_004605deszczyk.wav']\n",
            "------------Analiza nagrania: BUK4_20160922_005604.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1799\n",
            "Duration: 1798.002358276644\n",
            "ilość chunksów w tym nagraniu:  5137\n",
            "(40, 3)\n",
            "próbka  1461 zaczynajaca sie  511.34999999999997 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK4_20161016_035704.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1799\n",
            "Duration: 1798.002358276644\n",
            "ilość chunksów w tym nagraniu:  5137\n",
            "(28, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20161101_002104b.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1799\n",
            "Duration: 1798.002358276644\n",
            "ilość chunksów w tym nagraniu:  5137\n",
            "(273, 3)\n",
            "próbka  436 zaczynajaca sie  152.6 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "próbka  861 zaczynajaca sie  301.34999999999997 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "próbka  972 zaczynajaca sie  340.2 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "próbka  1075 zaczynajaca sie  376.25 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "próbka  2293 zaczynajaca sie  802.55 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "próbka  3421 zaczynajaca sie  1197.35 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "próbka  4573 zaczynajaca sie  1600.55 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "próbka  4576 zaczynajaca sie  1601.6 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK4_20161016_012704.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1799\n",
            "Duration: 1798.002358276644\n",
            "ilość chunksów w tym nagraniu:  5137\n",
            "(6, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK4_20161008_004605.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1798\n",
            "Duration: 1797.0009977324264\n",
            "ilość chunksów w tym nagraniu:  5134\n",
            "(43, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20161101_002104a.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1799\n",
            "Duration: 1798.002358276644\n",
            "ilość chunksów w tym nagraniu:  5137\n",
            "(147, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20181020_014805a.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1798\n",
            "Duration: 1797.0009977324264\n",
            "ilość chunksów w tym nagraniu:  5134\n",
            "(67, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK1_20181013$023504.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1799\n",
            "Duration: 1798.002358276644\n",
            "ilość chunksów w tym nagraniu:  5137\n",
            "(93, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20180921_015906b.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1797\n",
            "Duration: 1796.0025396825397\n",
            "ilość chunksów w tym nagraniu:  5132\n",
            "(55, 3)\n",
            "próbka  4285 zaczynajaca sie  1499.75 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "próbka  5024 zaczynajaca sie  1758.3999999999999 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20181103_011804.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1799\n",
            "Duration: 1798.002358276644\n",
            "ilość chunksów w tym nagraniu:  5137\n",
            "(49, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20181028_043105.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1798\n",
            "Duration: 1797.0009977324264\n",
            "ilość chunksów w tym nagraniu:  5134\n",
            "(58, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK1_20181011$001004.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1799\n",
            "Duration: 1798.002358276644\n",
            "ilość chunksów w tym nagraniu:  5137\n",
            "(169, 3)\n",
            "próbka  173 zaczynajaca sie  60.55 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "próbka  3272 zaczynajaca sie  1145.1999999999998 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "próbka  5043 zaczynajaca sie  1765.05 , jest unknown, bo za mały fragment głosu nas interesującego\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK4_20180925_224703.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1800\n",
            "Duration: 1799.0008163265306\n",
            "ilość chunksów w tym nagraniu:  5140\n",
            "(26, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20180909_010005.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1798\n",
            "Duration: 1797.0009977324264\n",
            "ilość chunksów w tym nagraniu:  5134\n",
            "(16, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK1_20180918$040704.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1799\n",
            "Duration: 1798.002358276644\n",
            "ilość chunksów w tym nagraniu:  5137\n",
            "(56, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20180921_015906a.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1797\n",
            "Duration: 1796.0025396825397\n",
            "ilość chunksów w tym nagraniu:  5132\n",
            "(57, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20181010_011205.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1798\n",
            "Duration: 1797.0009977324264\n",
            "ilość chunksów w tym nagraniu:  5134\n",
            "(41, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK4_20180913_201703.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1800\n",
            "Duration: 1799.0008163265306\n",
            "ilość chunksów w tym nagraniu:  5140\n",
            "(23, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20181014_233005.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1798\n",
            "Duration: 1797.0009977324264\n",
            "ilość chunksów w tym nagraniu:  5134\n",
            "(20, 3)\n",
            "Rozmiar  (7,)\n",
            "------------Analiza nagrania: BUK5_20181021_004605deszczyk.wav-----------\n",
            "Czas trwania nagrania - w sekundach: 1798\n",
            "Duration: 1797.0009977324264\n",
            "ilość chunksów w tym nagraniu:  5134\n",
            "(25, 3)\n",
            "Rozmiar  (7,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBXKlTQ0mvZE",
        "outputId": "27716c1a-040c-49d7-a16c-0dbf2a79781b"
      },
      "source": [
        "file_names_test_set_old, ind_for_test_set_old = create_set_ind(result_dataframe_test_old, balance_types[0], balance_ratios[0])\n",
        "file_names_test_set_new, ind_for_test_set_new = create_set_ind(result_dataframe_test_new, balance_types[0], balance_ratios[0])"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "full_rec\n",
            "20\n",
            "0  nagranie  BUK4_20160922_005604.wav\n",
            "pos:  58\n",
            "neg hałas: 10\n",
            "ind_chosen: 5135\n",
            "1  nagranie  BUK4_20161016_035704.wav\n",
            "pos:  15\n",
            "neg hałas: 19\n",
            "ind_chosen: 5131\n",
            "2  nagranie  BUK5_20161101_002104b.wav\n",
            "pos:  401\n",
            "neg hałas: 28\n",
            "ind_chosen: 5123\n",
            "3  nagranie  BUK4_20161016_012704.wav\n",
            "pos:  0\n",
            "neg hałas: 10\n",
            "ind_chosen: 5137\n",
            "4  nagranie  BUK4_20161008_004605.wav\n",
            "pos:  13\n",
            "neg hałas: 37\n",
            "ind_chosen: 5119\n",
            "5  nagranie  BUK5_20161101_002104a.wav\n",
            "pos:  160\n",
            "neg hałas: 46\n",
            "ind_chosen: 5113\n",
            "6  nagranie  BUK5_20181020_014805a.wav\n",
            "pos:  59\n",
            "neg hałas: 54\n",
            "ind_chosen: 5125\n",
            "7  nagranie  BUK1_20181013$023504.wav\n",
            "pos:  54\n",
            "neg hałas: 71\n",
            "ind_chosen: 5129\n",
            "8  nagranie  BUK5_20180921_015906b.wav\n",
            "pos:  73\n",
            "neg hałas: 18\n",
            "ind_chosen: 5128\n",
            "9  nagranie  BUK5_20181103_011804.wav\n",
            "pos:  8\n",
            "neg hałas: 72\n",
            "ind_chosen: 5133\n",
            "10  nagranie  BUK5_20181028_043105.wav\n",
            "pos:  30\n",
            "neg hałas: 57\n",
            "ind_chosen: 5123\n",
            "11  nagranie  BUK1_20181011$001004.wav\n",
            "pos:  201\n",
            "neg hałas: 61\n",
            "ind_chosen: 5125\n",
            "12  nagranie  BUK4_20180925_224703.wav\n",
            "pos:  11\n",
            "neg hałas: 28\n",
            "ind_chosen: 5138\n",
            "13  nagranie  BUK5_20180909_010005.wav\n",
            "pos:  9\n",
            "neg hałas: 13\n",
            "ind_chosen: 5131\n",
            "14  nagranie  BUK1_20180918$040704.wav\n",
            "pos:  38\n",
            "neg hałas: 45\n",
            "ind_chosen: 5129\n",
            "15  nagranie  BUK5_20180921_015906a.wav\n",
            "pos:  75\n",
            "neg hałas: 17\n",
            "ind_chosen: 5122\n",
            "16  nagranie  BUK5_20181010_011205.wav\n",
            "pos:  29\n",
            "neg hałas: 29\n",
            "ind_chosen: 5126\n",
            "17  nagranie  BUK4_20180913_201703.wav\n",
            "pos:  5\n",
            "neg hałas: 33\n",
            "ind_chosen: 5140\n",
            "18  nagranie  BUK5_20181014_233005.wav\n",
            "pos:  12\n",
            "neg hałas: 11\n",
            "ind_chosen: 5126\n",
            "19  nagranie  BUK5_20181021_004605deszczyk.wav\n",
            "pos:  14\n",
            "neg hałas: 23\n",
            "ind_chosen: 5129\n",
            "wszystkich chunków:  102562 , w tym  1265  pozytywnych. Czyli  1.23  % pozytywnych w zbiorze full_rec\n",
            "full_rec\n",
            "18\n",
            "0  nagranie  BUK4_20160922_005604.wav\n",
            "pos:  58\n",
            "neg hałas: 10\n",
            "ind_chosen: 5135\n",
            "1  nagranie  BUK4_20180913_201703.wav\n",
            "pos:  5\n",
            "neg hałas: 33\n",
            "ind_chosen: 5140\n",
            "2  nagranie  BUK5_20181021_004605deszczyk.wav\n",
            "pos:  14\n",
            "neg hałas: 23\n",
            "ind_chosen: 5129\n",
            "3  nagranie  BUK4_20161008_004605.wav\n",
            "pos:  13\n",
            "neg hałas: 37\n",
            "ind_chosen: 5119\n",
            "4  nagranie  BUK5_20181010_011205.wav\n",
            "pos:  29\n",
            "neg hałas: 29\n",
            "ind_chosen: 5126\n",
            "5  nagranie  BUK5_20181028_043105.wav\n",
            "pos:  30\n",
            "neg hałas: 57\n",
            "ind_chosen: 5123\n",
            "6  nagranie  BUK1_20181013$023504.wav\n",
            "pos:  54\n",
            "neg hałas: 71\n",
            "ind_chosen: 5129\n",
            "7  nagranie  BUK5_20180921_015906a.wav\n",
            "pos:  75\n",
            "neg hałas: 17\n",
            "ind_chosen: 5122\n",
            "8  nagranie  BUK1_20181011$001004.wav\n",
            "pos:  201\n",
            "neg hałas: 61\n",
            "ind_chosen: 5125\n",
            "9  nagranie  BUK5_20181103_011804.wav\n",
            "pos:  8\n",
            "neg hałas: 72\n",
            "ind_chosen: 5133\n",
            "10  nagranie  BUK4_20161016_035704.wav\n",
            "pos:  15\n",
            "neg hałas: 19\n",
            "ind_chosen: 5131\n",
            "11  nagranie  BUK5_20180909_010005.wav\n",
            "pos:  9\n",
            "neg hałas: 13\n",
            "ind_chosen: 5131\n",
            "12  nagranie  BUK5_20181014_233005.wav\n",
            "pos:  12\n",
            "neg hałas: 11\n",
            "ind_chosen: 5126\n",
            "13  nagranie  BUK5_20180921_015906b.wav\n",
            "pos:  73\n",
            "neg hałas: 18\n",
            "ind_chosen: 5128\n",
            "14  nagranie  BUK5_20181020_014805a.wav\n",
            "pos:  59\n",
            "neg hałas: 54\n",
            "ind_chosen: 5125\n",
            "15  nagranie  BUK1_20180918$040704.wav\n",
            "pos:  38\n",
            "neg hałas: 45\n",
            "ind_chosen: 5129\n",
            "16  nagranie  BUK4_20180925_224703.wav\n",
            "pos:  11\n",
            "neg hałas: 28\n",
            "ind_chosen: 5138\n",
            "17  nagranie  BUK4_20161016_012704.wav\n",
            "pos:  0\n",
            "neg hałas: 10\n",
            "ind_chosen: 5137\n",
            "wszystkich chunków:  92326 , w tym  704  pozytywnych. Czyli  0.76  % pozytywnych w zbiorze full_rec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmID4sDTr50F",
        "outputId": "c8c8dad1-f47f-47d9-9f29-3ff570dcc93d"
      },
      "source": [
        "print(len(result_dataframe_test_new['chunk_ids'][0]))\n",
        "all_chunks_chosen =0\n",
        "all_chuks_ever = 0\n",
        "\n",
        "for i in range(18):\n",
        "  all_chuks_ever += len(result_dataframe_test_new['chunk_ids'][i])\n",
        "  all_chunks_chosen +=  len(ind_for_test_set_new[i])\n",
        "#.sum()\n",
        "print(all_chunks_chosen)\n",
        "print(all_chuks_ever)\n",
        "print('Chunksy unknown, różnica: ', all_chuks_ever - all_chunks_chosen)"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5137\n",
            "92326\n",
            "92441\n",
            "Chunksy unknown, różnica:  115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F96of4-ewgIF",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# do sprawdzenia czy te zagnieżdżone listy w call_id i chunks_species działają\n",
        "\n",
        "def isListEmpty(inList):\n",
        "  for elem in inList:\n",
        "    if elem: # Is a list\n",
        "        print(elem)\n",
        "        #return all( map(isListEmpty, inList) )\n",
        "    #return False # Not a list\n",
        "\n",
        "isListEmpty(result_dataframe['call_id'][2])\n",
        "isListEmpty(result_dataframe['chunks_species'][2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h047_V8wnno",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# do sprawdzenia jakie ID mają głosy w naszym nagraniu (każdy z labeli ma ID, nie tylko głosy, dlatego nie wszystkie liczby tu będą)\n",
        "\n",
        "test_list = result_dataframe['call_id'][2]\n",
        "\n",
        "#print(\"The original list : \" + str(test_list)) \n",
        "  \n",
        "res = [] \n",
        "temp = set() \n",
        "for inner in test_list: \n",
        "        for ele in inner: \n",
        "            if not ele in temp: \n",
        "                temp.add(ele) \n",
        "                res.append(ele) \n",
        "  \n",
        "print(\"Unique elements in nested tuples are : \" + str(res)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQMba835eVQ5"
      },
      "source": [
        "--------------------------------------------------------------------------------\n",
        "\n",
        "**Wybór nagrań do walida**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3SNsC4HCrdi"
      },
      "source": [
        "rec_for_train = [ 181006, 181007, 181001, 181002, 161103, 161104, 160925, 160926, 161031, 161005, 160918 ] \n",
        "labels_s = ['s', 's?']\n",
        "labels_k = ['k', 'k?']\n",
        "labels_d = ['d', 'd?']\n",
        "labels_r = ['r', 'r?']\n",
        "calls_1 = ['d', 'd?', 'k', 'k?', 'kwiczol', 'r','r?', 's', 's?', 'skowronek', 'ni']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIMXBag0ApoF"
      },
      "source": [
        "# Podstawowy wybór nagrań treningowych i walidacyjnych praz zbiór testowy: stare 20 nagrań, nowe 18 nagrań\n",
        "\n",
        "all_rec_dates_train, all_rec_dates_test = [],[]\n",
        "potential_valid_rec = []\n",
        "basic_train_rec = []\n",
        "test_new_rec,test_old_rec = [], []\n",
        "\n",
        "for file_name in file_names_train:\n",
        "\n",
        "  recording_date = str(file_name.split('_20')[1][0:6])\n",
        "  all_rec_dates_train.append(int(recording_date))\n",
        "  if int(recording_date) not in rec_for_train:\n",
        "    potential_valid_rec.append(file_name.split('.')[0])\n",
        "  else:\n",
        "    basic_train_rec.append(file_name.split('.')[0]) \n",
        "    \n",
        "print(all_rec_dates_train)\n",
        "print(potential_valid_rec)\n",
        "print(basic_train_rec)\n",
        "\n",
        "for file_name in file_names_test:\n",
        "\n",
        "  recording_date = str(file_name.split('_20')[1][0:6])\n",
        "  all_rec_dates_test.append(int(recording_date))\n",
        "  test_old_rec.append(file_name.split('.')[0])\n",
        "  if int(recording_date) != 161101:\n",
        "    test_new_rec.append(file_name.split('.')[0])\n",
        "\n",
        "print(test_new_rec)\n",
        "print(test_old_rec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lR3r7yQHqym"
      },
      "source": [
        "count_ratio_valid = find_ratio(potential_valid_rec, path_train161718_txt)  \n",
        "count_ratio_train = find_ratio(basic_train_rec, path_train161718_txt)\n",
        "count_ratio_test_old= find_ratio(test_old_rec, path_test1618_txt)  # wszystkie 20 nagrań\n",
        "count_ratio_test_new= find_ratio(test_new_rec, path_test1618_txt)  # bez tych 2 zawierających dużo k, czyli 18 nagrań\n",
        "\n",
        "print('Ratio s : k : d : r')\n",
        "print('Valid (31): ', count_ratio_valid[0],' : ',count_ratio_valid[1],' : ',count_ratio_valid[2],' : ',count_ratio_valid[3],'. Ratio s:k - ', count_ratio_valid[0]/count_ratio_valid[1])  \n",
        "print('Train (63): ', count_ratio_train[0],' : ',count_ratio_train[1],' : ',count_ratio_train[2],' : ',count_ratio_train[3], '. Ratio s:k - ', count_ratio_train[0]/count_ratio_train[1])  \n",
        "print('Test old (20): ', count_ratio_test_old[0],' : ',count_ratio_test_old[1],' : ',count_ratio_test_old[2],' : ',count_ratio_test_old[3], '. Ratio s:k - ', count_ratio_test_old[0]/count_ratio_test_old[1])  \n",
        "print('Test new (18): ',count_ratio_test_new[0],' : ',count_ratio_test_new[1],' : ',count_ratio_test_new[2],' : ',count_ratio_test_new[3], '. Ratio s:k - ', count_ratio_test_new[0]/count_ratio_test_new[1])  \n",
        "\n",
        "#print(np.shape(potential_valid_dates))\n",
        "#print(np.shape(basic_train_rec))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W20Hl8eSAxs5"
      },
      "source": [
        "import random\n",
        "\n",
        "## funkcja losująca 8 nagrań do walida (z 31), resztę wrzucająca do traina, przeliczenie score\n",
        "# scorer = stosunek s:k najważniejszy, a tak z 1/5 wagi na d\n",
        "scorer_best, scorer = 10, 10\n",
        "\n",
        "for i in range(1000):\n",
        "\n",
        "  random_valid_rec = random.sample(potential_valid_rec, 8)\n",
        "  remaining_train_rec = []\n",
        "\n",
        "\n",
        "  #print(random_valid_rec)\n",
        "\n",
        "  for file_name in file_names_train:\n",
        "    #print(file_name)\n",
        "    if (file_name.split('.')[0]) not in random_valid_rec:\n",
        "    #print(file_name)\n",
        "      remaining_train_rec.append(file_name.split('.')[0])\n",
        "\n",
        "    \n",
        "  count_ratio_valid_8 = find_ratio(random_valid_rec, path_train161718_txt)\n",
        "  count_ratio_train63_23 = find_ratio(remaining_train_rec, path_train161718_txt)\n",
        "\n",
        "  #print(np.shape(remaining_train_rec))\n",
        "  #print(np.shape(random_valid_rec))\n",
        "  #print((remaining_train_rec))\n",
        "  #print((random_valid_rec))\n",
        "  if (count_ratio_valid_8[2]!=0):\n",
        "    scorer_kd = 0.2*abs((count_ratio_train63_23[1]/count_ratio_train63_23[2]) - ( count_ratio_valid_8[1]/count_ratio_valid_8[2] ))\n",
        "  else:\n",
        "    scorer_kd = 666\n",
        "\n",
        "  if (count_ratio_valid_8[1]!=0):\n",
        "    scorer_sk = abs((count_ratio_train63_23[0]/count_ratio_train63_23[1]) - ( count_ratio_valid_8[0]/count_ratio_valid_8[1] ) )\n",
        "  else:\n",
        "    scorer_sk = 1000000  \n",
        "\n",
        "  scorer = scorer_sk + scorer_kd\n",
        "\n",
        "  print(scorer)\n",
        "  if scorer_best > scorer:\n",
        "    print(i)\n",
        "    print('scorer: ', scorer)\n",
        "    print('Valid ratio s:k - ', count_ratio_valid_8[0]/count_ratio_valid_8[1])\n",
        "    print('Train ratio s:k - ', count_ratio_train63_23[0]/count_ratio_train63_23[1])\n",
        "    print('Valid ratio k:d - ', count_ratio_valid_8[1]/count_ratio_valid_8[2])\n",
        "    print('Train ratio k:d - ', count_ratio_train63_23[1]/count_ratio_train63_23[2])\n",
        "    scorer_best =  scorer\n",
        "    validate_rec_best = random_valid_rec\n",
        "    count_ratio_valid_best = count_ratio_valid_8\n",
        "    count_ratio_train_best = count_ratio_train63_23\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8T77jFs0tjs"
      },
      "source": [
        "print(validate_rec_best)\n",
        "print('Valid (8): ', count_ratio_valid_best[0],' : ',count_ratio_valid_best[1],' : ',count_ratio_valid_best[2],' : ',count_ratio_valid_best[3],'. Ratio s:k - ', count_ratio_valid_best[0]/count_ratio_valid_best[1], 'Ratio k:d - ', count_ratio_valid_best[1]/count_ratio_valid_best[2], 'Ratio d:r - ', count_ratio_valid_best[2]/count_ratio_valid_best[3])  \n",
        "print('Train (86): ', count_ratio_train_best[0],' : ',count_ratio_train_best[1],' : ',count_ratio_train_best[2],' : ',count_ratio_train_best[3], '. Ratio s:k - ', count_ratio_train_best[0]/count_ratio_train_best[1], 'Ratio k:d - ', count_ratio_train_best[1]/count_ratio_train_best[2], 'Ratio d:r - ', count_ratio_train_best[2]/count_ratio_train_best[3])  \n",
        "\n",
        "## Upewnić się że się daty nie pokrywają\n",
        "validate_rec_best_dates = []\n",
        "rec_dates_train, rec_dates_valid = [],[]\n",
        "\n",
        "for file_name in validate_rec_best:\n",
        "  recording_date = str(file_name.split('_20')[1][0:6])\n",
        "  validate_rec_best_dates.append(recording_date)\n",
        "\n",
        "print(validate_rec_best_dates)\n",
        "\n",
        "for file_name in file_names_train:\n",
        "  #print(file_name)\n",
        "  recording_date = str(file_name.split('_20')[1][0:6])\n",
        "  #print(recording_date)\n",
        "  if (recording_date) in validate_rec_best_dates:\n",
        "    rec_dates_valid.append(recording_date)\n",
        "  else:  # final trening 88\n",
        "    rec_dates_train.append(recording_date) \n",
        "# Nie pokrywają się\n",
        "\n",
        "#Counter(rec_dates_valid)\n",
        "#Counter(rec_dates_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHYrHqUI3Rtj"
      },
      "source": [
        "### TO JEST OD DZIŚ MÓJ WALID\n",
        "\n",
        "valid_set = ['9niski_szum_BUK4_20161025_000604', 'BUK5_20180930_000704', 'BUK4_20161024_223604', 'BUK4_20171001_020404a', 'BUK1_20160914_011604', 'BUK5_20170910_025605', 'BUK4_20161013_200104', 'BUK5_20181003_235705']\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}